{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunkaraboinaPraveenKumar/Machine_Learning_Projects/blob/main/self_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langgraph langchain_groq langchain_huggingface langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ6qV95PByCL",
        "outputId": "992a483f-630f-42fa-fe5e-25c558439781"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.2.66)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.11/dist-packages (0.2.3)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.10)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.51)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.15.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.27.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.47.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain) (3.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community\n",
        "!pip install duckduckgo-search\n",
        "!pip install tiktoken\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csR-Du5aB0eJ",
        "outputId": "7ba6d85c-44fc-409c-b3bc-95fec6c11176"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.15)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.31 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.31)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.15->langchain_community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.31->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.31->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.15->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Collecting duckduckgo-search\n",
            "  Using cached duckduckgo_search-7.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Collecting primp>=0.10.0 (from duckduckgo-search)\n",
            "  Using cached primp-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.0)\n",
            "Using cached duckduckgo_search-7.2.1-py3-none-any.whl (19 kB)\n",
            "Using cached primp-0.10.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Installing collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-7.2.1 primp-0.10.1\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.5)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.9.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.69.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.14)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.9.0-py2.py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=af468f50795c689bc2951212fdbf63af82f1c19ee2417455797f9fdf2e73a711\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, coloredlogs, build, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.9.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.3 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dwxW2OK-Bw1N"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GROQ_API_KEY']=userdata.get('groq_api_key')\n",
        "os.environ['HF_TOKEN']=userdata.get('HF_TOKEN')\n",
        "llm = ChatGroq(model_name=\"Gemma2-9b-It\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NjggT4eNBw1S"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "27083a2470134b2fafb45f94cc1a3b95",
            "a1335abbb7b6467b88130efaa6526a1c",
            "2fc7a928f3d74fdeb9e5d081eacad808",
            "955fe0d4d4c849f59d287c90bf90d716",
            "908b53c275e748d48c8d8778434d01e5",
            "67a81c31257542ebbdccd2d9a3c38c83",
            "12b45a8f25f14ceb8d387a364166ed22",
            "4281dfaca00544a297d0c2ab14d31400",
            "3349d880c6d3485a8cc92a2408d82341",
            "0640e5cd238341b1ac49431d5d074a37",
            "d97f4885648343a3b3d2bef44f9d0813",
            "6e49dc12b32445c69367e02c9274b7cd",
            "4eb40f30b2c04bd2a44121e2d7c4b9b7",
            "01543f0d2cb949e9b75ad57a53794415",
            "6d751f8a1b9140cb87dcf3d8de4688c4",
            "66c2b702ed504ea98fe769fa332ad7ec",
            "388ea664ba8e4e0c966d14572d2cf44a",
            "7424ca6b3e9a4955a792693c507273f3",
            "a45668a43f544f39995b0786baecc014",
            "1a49ad4ea5c34342acc8d28afdbaa019",
            "c0feedebb4134c82abbe364af6edf0d3",
            "fe75f0d5157d4ad1bb9cb933409e5a22",
            "45fa10027e874587a6903fa734fb87e2",
            "c1ae736823a84be7b815f6e0054c4c44",
            "cf6cabc6900142a3abd1aa951c2fb675",
            "ffbd6cb3ac0842a7bad21b6486feb6df",
            "7d8970b37355436d89f4fc3733677927",
            "d64db5cfb92b4a4dbb392b437b0d0496",
            "de2936151e83499e969c324866477d51",
            "04a52c6e860c4986b0aa546e5c32add8",
            "ec4f8eafb2b141aeaa0b538d8edaf519",
            "2f54faabce004b3594c74eed3c6d2373",
            "64b3491fd65643119daa9be16020c7e3",
            "b63c5f9c57644fe0ba03fb54fd664a95",
            "b3b630c903ea497bbfab04ad5641a9d2",
            "f875629344af44058df0dc6851fb369d",
            "b0605807ce5245248da119b73fd54ea6",
            "893655cec0714274b3c39d87c68c37e5",
            "27bc9a01bed84859a828d56b8ca8ea90",
            "c936e9d84e96480e80114444721e28c0",
            "57a2dfc89df14081a216690e0da3cf40",
            "273ca287ef7c4b1c871617c099177241",
            "804c4e02e2ce47199e6f1150810f863a",
            "f77158f6ca9543e89915a2089bb31cd8",
            "074a29b8f1e14cea8ce63eba0b89236d",
            "00d1bb4ea0de4cc19de903bf131055d7",
            "63e524a5e7d54906b74baa73fb1f4771",
            "02a2fa37da754edfa279229a0f8c33af",
            "dfbed2653b7b49cca43ffa14cb4b08cb",
            "9a9b62ae15684a19ab9064e32e35487a",
            "af3dd13038dd49e69e630439a1f25e71",
            "121d027da5df459fad95ab85929252a6",
            "a8670c3b388e4445b6effe6fa64eaaab",
            "85dbd3efca274ed69a3db69e0d7cda0c",
            "b3d9ae034ac34668953fd42b75219376",
            "a683250fa9cc46a2a2dee63d73cb98d9",
            "1967f63ebd0f4bf0848f49e2646f74aa",
            "5f615e7241a74496b5c94754c5576246",
            "e534fcda54894af7b162a860637f744e",
            "46b403937a7c48dd8561b224729f5bc3",
            "d76cf8cbf2fb41efb913a9c7729ef1dd",
            "7d39fe0bc6a24b87a8beb5071f47a8fa",
            "2d7e43276e7f483d841621d6786e843b",
            "2e6447c8d5bf41ef855eb7d7ae2a596b",
            "13a9e83c139a4b9fa2f90983693e2b32",
            "e07a81bb7a714f07a00c6ce9026bb7eb",
            "9414717cc649496681ec80126da3ef61",
            "4c6f89f3503a4b5db3e241d264f8e18e",
            "4c6961f25f7b49779acfc9b663415d61",
            "cae7290a44734d878c680760589e0fe7",
            "d4fd08552ca84b4e9a2b844baacc8ece",
            "dda21ff6fcaa46db8a91ac1fc043ca36",
            "351b955d288b451d835b935cd3887bff",
            "c973df50712a454b8a3c8a01ddaa6557",
            "9011fc516dbe42b8883a3a2260c41d18",
            "edfa1145f1d847ad8916a15133856e44",
            "5613a8962e494332a2a769beeed1f37a",
            "f7ce43d15c37421bb8acb52f1ee4cda7",
            "85d9ae3899f94f179e2961ff4b0589da",
            "3ff6d9a74ac44daba464dca2e7cb4a86",
            "c7ad40add5394b659508d5b2c6eca34d",
            "2be37cd4c3894c37a19bbbaf2acf306f",
            "1b6f009684df4d819fd5b72a0517a4bd",
            "a4091215c71e4450981999a2680f9686",
            "1fc9026b959b4db6904705243972793b",
            "755a3818c94844779f2223236b107f6c",
            "e942e31eadc94bc2addcd88f668affe4",
            "ec6dccdc909c44278e9940ee24a09679",
            "f868af1bb5324daead6bb34e27b21bff",
            "cd547f13269340d1b3e7f4d445d3f533",
            "7d755fe2b905465a895369e67401343a",
            "67483644ca094d439af2153121a5b0fd",
            "dc40c684690f4832aaf1b1cddafb7eac",
            "eeec603384c344958f7634816ca41e1c",
            "b5c261340b314b5b8c562915134f63d5",
            "0b4780df0be24c23a80f87b1929269d8",
            "3cbe2ec957ff4ff0ad51d8b4356f338e",
            "fdfe3d6c967a45eaa37a0b15ebaa939c",
            "3313e105a1cf4c21be203d13825cdbed",
            "e1ff6efc0d42400fa621f3a7198afe00",
            "a834370aa22b438f97e23e3b7a99ca82",
            "9c7e7bac37ed4d5e8eb10e2ec328c097",
            "8cd5bd7bc2b244feb59c0c5ddd237505",
            "ceeba63681e04aa0b1538db50c3a11ad",
            "43195e09702c48019bafcf93286753f6",
            "192dce2989304f1d9d648e5e2efed6a5",
            "054ff1468a204087b2b8e5340f574320",
            "e0e57558d8504b5db4ee26242b1d3811",
            "1850d3c295c74753bb7232dc976fbd73",
            "babcc9b4b5654f5e8b7d167493cc1d81",
            "1fea2049e512492ca2eb0e32707ac00d",
            "2f4eaa2f16964eb59c8b501e913a0dcb",
            "f24b7830eeea4c7ab1801bee9830a0c0",
            "ac3fc9e1dd0641148c724f4dad61df49",
            "325a9a169ec2419898d0440d2fafd674",
            "a5c6f998695148e9a470d7eb4e4a49ed",
            "1a2f39af53044ec798c353898667f29e",
            "468b35ad872944969ada599122bf118e",
            "203975b69e514efbadeac8bed565b3ca",
            "31a7ca84b5d44d08b47b034eb4aead09",
            "b21c1370c37f44deb1bd9f54f147c07b"
          ]
        },
        "id": "ac9y4aFvBw1U",
        "outputId": "824a2fe8-5c8e-48bd-fb30-0dec477ec8dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27083a2470134b2fafb45f94cc1a3b95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e49dc12b32445c69367e02c9274b7cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45fa10027e874587a6903fa734fb87e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b63c5f9c57644fe0ba03fb54fd664a95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "074a29b8f1e14cea8ce63eba0b89236d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a683250fa9cc46a2a2dee63d73cb98d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9414717cc649496681ec80126da3ef61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7ce43d15c37421bb8acb52f1ee4cda7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f868af1bb5324daead6bb34e27b21bff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1ff6efc0d42400fa621f3a7198afe00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fea2049e512492ca2eb0e32707ac00d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "llm=ChatGroq(model_name=\"Gemma2-9b-It\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "o78EOOhKBw1V"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=100, chunk_overlap=50\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# Add to vectorDB\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    embedding=embeddings,\n",
        ")\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FSGTNInvBw1Y"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"retrieve_blog_posts\",\n",
        "    \"Search and return information about Lilian Weng blog posts on LLM agents, prompt engineering, and adversarial attacks on LLMs.\",\n",
        ")\n",
        "\n",
        "tools = [retriever_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYG-eJv6Bw1Z"
      },
      "source": [
        "#### Let's look into the retriever grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "pSo8MRNcBw1b"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "N6Lp7RUXBw1c"
      },
      "outputs": [],
      "source": [
        "# LLM with function call\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "INVlDf4HBw1c"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "system = \"\"\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..\n",
        "If the document has words or meanings related to the question, mark it as relevant.\n",
        "Give a simple 'yes' or 'no' answer to show if the document is relevant or not.\"\"\"\n",
        "\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmJ4u5RLBw1e",
        "outputId": "712761e5-fbc8-49cd-8261-3cd5bea557d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a grader checking if a document is relevant to a user’s question.The check has to be done very strictly..  \\nIf the document has words or meanings related to the question, mark it as relevant.  \\nGive a simple 'yes' or 'no' answer to show if the document is relevant or not.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['document', 'question'], input_types={}, partial_variables={}, template='Retrieved document: \\n\\n {document} \\n\\n User question: {question}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "grade_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "fARM6_ZyBw1f"
      },
      "outputs": [],
      "source": [
        "my_retrieval_grader = grade_prompt | structured_llm_grader\n",
        "question = \"what is ai agent?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "TUMOOzAdBw1f"
      },
      "outputs": [],
      "source": [
        "\n",
        "docs = retriever.get_relevant_documents(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UTKtqkGBw1g",
        "outputId": "f044ee79-673b-4314-ef16-22c9135a5490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'),\n",
              " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'),\n",
              " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.'),\n",
              " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.')]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "dKRE5plzBw1g"
      },
      "outputs": [],
      "source": [
        "doc_txt = docs[2].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "QnWUynoUBw1h",
        "outputId": "f727e9ff-40bd-49a2-c450-3dffa0f3d584"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "doc_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeXn0jFSBw1h",
        "outputId": "4e04004b-0a57-4494-ed34-cc925110d847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\": question}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "jNxUXdngBw1h"
      },
      "outputs": [],
      "source": [
        "question=\"who is sunny svaita?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vhuy6OuBw1i",
        "outputId": "88b5e1e3-b52a-4a2c-a0c2-675149270333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='no'\n"
          ]
        }
      ],
      "source": [
        "print(my_retrieval_grader.invoke({\"document\":doc_txt,\"question\": question}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeNlTQEABw1i"
      },
      "source": [
        "### let's look into the data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "HxMs_qMGBw1j"
      },
      "outputs": [],
      "source": [
        "### Generate\n",
        "\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r7TuQjmBw1j",
        "outputId": "54c26ff8-1296-4074-d1f8-d5b8455e79ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
            "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCUZ2VrQBw1j",
        "outputId": "fd2115d4-4195-4fcb-f859-34f0370b5be2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'),\n",
              " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'),\n",
              " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.'),\n",
              " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Generative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.')]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "SCScmabABw1k"
      },
      "outputs": [],
      "source": [
        "rag_chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "gvhuT5m7Bw1l"
      },
      "outputs": [],
      "source": [
        "question=\"what is a AI agent?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "XeZwQkVIBw1l"
      },
      "outputs": [],
      "source": [
        "# Run\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mpBw07yBw1m",
        "outputId": "09ba3e7e-a112-4cbd-8bab-aee108f8296b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='An AI agent is a system with a large language model (LLM) as its core, capable of planning, remembering, and using tools to accomplish tasks.  These agents can break down complex problems into smaller steps and learn from their experiences to improve their performance. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 2066, 'total_tokens': 2123, 'completion_time': 0.103636364, 'prompt_time': 0.085860685, 'queue_time': 0.02441258099999999, 'total_time': 0.189497049}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-aa269025-cee6-4b70-b184-a259763e11ea-0', usage_metadata={'input_tokens': 2066, 'output_tokens': 57, 'total_tokens': 2123})"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWW-laWxBw1n"
      },
      "source": [
        "### Hallucination Grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "pSPDmsjHBw1n"
      },
      "outputs": [],
      "source": [
        "# Data model\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "6MwRHdiJBw1o"
      },
      "outputs": [],
      "source": [
        "# LLM with function call\n",
        "structured_llm_grader = llm.with_structured_output(GradeHallucinations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "qB86LQ31Bw1o"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "system = \"\"\"You are a grader checking if an LLM generation is grounded in or supported by a set of retrieved facts.\n",
        "Give a simple 'yes' or 'no' answer. 'Yes' means the generation is grounded in or supported by a set of retrieved the facts.\"\"\"\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "HEoqPdgyBw1p"
      },
      "outputs": [],
      "source": [
        "hallucinations_grader = hallucination_prompt | structured_llm_grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OcBsz-UBw1p",
        "outputId": "a4533747-b7ad-473a-8787-a494a239a0be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "print(hallucinations_grader.invoke({\"documents\": docs, \"generation\": generation}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5AXU2wGBw1r"
      },
      "source": [
        "#### Answer Grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XZ6UM76Bw1s",
        "outputId": "bec03586-7bad-4f7f-e7fa-f7f714ce6d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "### Answer Grader\n",
        "# Data model\n",
        "class GradeAnswer(BaseModel):\n",
        "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n",
        "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
        "answer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "answer_grader = answer_prompt | structured_llm_grader\n",
        "print(answer_grader.invoke({\"question\": question, \"generation\": generation}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjxqbHL7Bw1t"
      },
      "source": [
        "### Question Re-writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "xv3HBC3fBw1t"
      },
      "outputs": [],
      "source": [
        "system = \"\"\"You are a question re-writer that converts an input question into a better optimized version for vector store retrieval document.\n",
        "You are given both a question and a document.\n",
        "- First, check if the question is relevant to the document by identifying a connection or relevance between them.\n",
        "- If there is a little relevancy, rewrite the question based on the semantic intent of the question and the context of the document.\n",
        "- If no relevance is found, simply return this single word \"question not relevant.\" dont return the entire phrase\n",
        "Your goal is to ensure the rewritten question aligns well with the document for better retrieval.\"\"\"\n",
        "\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\"\"\"Here is the initial question: \\n\\n {question} \\n,\n",
        "             Here is the document: \\n\\n {documents} \\n ,\n",
        "             Formulate an improved question. if possible other return 'question not relevant'.\"\"\"\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "question_rewriter = re_write_prompt | llm | StrOutputParser()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qDK6jAVjBw1u"
      },
      "outputs": [],
      "source": [
        "question=\"who is a current indian prime minister?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7Zov2d75Bw1u",
        "outputId": "b314904e-416e-435e-f366-a2a40623f095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'question not relevant \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "question_rewriter.invoke({\"question\":question,\"documents\":docs})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "LByxr-MvBw15"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "class AgentState(TypedDict):\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[str]\n",
        "    filter_documents: List[str]\n",
        "    unfilter_documents: List[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "__8kGJLxBw16"
      },
      "outputs": [],
      "source": [
        "def retrieve(state:AgentState):\n",
        "    print(\"----RETRIEVE----\")\n",
        "    question=state['question']\n",
        "    documents=retriever.get_relevant_documents(question)\n",
        "    return {\"documents\": documents, \"question\": question}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "8YP5j5-hBw16"
      },
      "outputs": [],
      "source": [
        "def grade_documents(state:AgentState):\n",
        "    print(\"----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\")\n",
        "    question = state['question']\n",
        "    documents = state['documents']\n",
        "\n",
        "    filtered_docs = []\n",
        "    unfiltered_docs = []\n",
        "    for doc in documents:\n",
        "        score=my_retrieval_grader.invoke({\"question\":question, \"document\":doc})\n",
        "        grade=score.binary_score\n",
        "\n",
        "        if grade=='yes':\n",
        "            print(\"----GRADE: DOCUMENT RELEVANT----\")\n",
        "            filtered_docs.append(doc)\n",
        "        else:\n",
        "            print(\"----GRADE: DOCUMENT NOT RELEVANT----\")\n",
        "            unfiltered_docs.append(doc)\n",
        "    if len(unfiltered_docs)>1:\n",
        "        return {\"unfilter_documents\": unfiltered_docs,\"filter_documents\":[], \"question\": question}\n",
        "    else:\n",
        "        return {\"filter_documents\": filtered_docs,\"unfilter_documents\":[],\"question\": question}\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "-rMPwAYkBw17"
      },
      "outputs": [],
      "source": [
        "def decide_to_generate(state:AgentState):\n",
        "    print(\"----ACCESS GRADED DOCUMENTS----\")\n",
        "    state[\"question\"]\n",
        "    unfiltered_documents = state[\"unfilter_documents\"]\n",
        "    filtered_documents = state[\"filter_documents\"]\n",
        "\n",
        "\n",
        "    if unfiltered_documents:\n",
        "        print(\"----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\")\n",
        "        return \"transform_query\"\n",
        "    if filtered_documents:\n",
        "        print(\"----DECISION: GENERATE----\")\n",
        "        return \"generate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "hRwHcPXaBw1-"
      },
      "outputs": [],
      "source": [
        "def generate(state:AgentState):\n",
        "    print(\"----GENERATE----\")\n",
        "    question=state[\"question\"]\n",
        "    documents=state[\"documents\"]\n",
        "\n",
        "    generation = rag_chain.invoke({\"context\": documents,\"question\":question})\n",
        "    return {\"documents\":documents,\"question\":question,\"generation\":generation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "kyC_c2KJBw1-"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "def transform_query(state:AgentState):\n",
        "    question=state[\"question\"]\n",
        "    documents=state[\"documents\"]\n",
        "\n",
        "    print(f\"this is my document{documents}\")\n",
        "    response = question_rewriter.invoke({\"question\":question,\"documents\":documents})\n",
        "    print(f\"----RESPONSE---- {response}\")\n",
        "    if response == 'question not relevant':\n",
        "        print(\"----QUESTION IS NOT AT ALL RELEVANT----\")\n",
        "        return {\"documents\":documents,\"question\":response,\"generation\":\"question was not at all relevant\"}\n",
        "    else:\n",
        "        return {\"documents\":documents,\"question\":response}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "LEbtGK4ABw1_"
      },
      "outputs": [],
      "source": [
        "def decide_to_generate_after_transformation(state:AgentState):\n",
        "    question=state[\"question\"]\n",
        "\n",
        "    if question==\"question not relevant\":\n",
        "        return \"query_not_at_all_relevant\"\n",
        "    else:\n",
        "        return \"Retriever\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "kgqyozXdBw2A"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "def grade_generation_vs_documents_and_question(state:AgentState):\n",
        "    print(\"---CHECK HELLUCINATIONS---\")\n",
        "    question= state['question']\n",
        "    documents = state['documents']\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    score = hallucinations_grader.invoke({\"documents\":documents,\"generation\":generation})\n",
        "\n",
        "    grade = score.binary_score\n",
        "\n",
        "    #Check hallucinations\n",
        "    if grade=='yes':\n",
        "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
        "\n",
        "        print(\"---GRADE GENERATION vs QUESTION ---\")\n",
        "\n",
        "        score = answer_grader.invoke({\"question\":question,\"generation\":generation})\n",
        "\n",
        "        grade = score.binary_score\n",
        "\n",
        "        if grade=='yes':\n",
        "            print(\"---DECISION: GENERATION ADDRESS THE QUESTION ---\")\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
        "            return \"not useful\"\n",
        "    else:\n",
        "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\")\n",
        "        \"not useful\"\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6OGWvLTBw2D"
      },
      "source": [
        "### From here the Langgraph workflow will start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oewQ4BsCBw2D",
        "outputId": "e6d244c7-7fe6-4999-b1e2-f0482f425818"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78ab79070910>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"Docs_Vector_Retrieve\", retrieve)\n",
        "workflow.add_node(\"Grading_Generated_Documents\", grade_documents)\n",
        "workflow.add_node(\"Content_Generator\", generate)\n",
        "workflow.add_node(\"Transform_User_Query\", transform_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0SJiQNWBw2E",
        "outputId": "723dcf1f-35df-40da-f078-abd2622de18b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78ab79070910>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "workflow.add_edge(START,\"Docs_Vector_Retrieve\")\n",
        "workflow.add_edge(\"Docs_Vector_Retrieve\",\"Grading_Generated_Documents\")\n",
        "workflow.add_conditional_edges(\"Grading_Generated_Documents\",\n",
        "                            decide_to_generate,\n",
        "                            {\n",
        "                            \"generate\": \"Content_Generator\",\n",
        "                            \"transform_query\": \"Transform_User_Query\"\n",
        "                            }\n",
        "                            )\n",
        "workflow.add_conditional_edges(\"Content_Generator\",\n",
        "                            grade_generation_vs_documents_and_question,\n",
        "                            {\n",
        "                            \"useful\": END,\n",
        "                            \"not useful\": \"Transform_User_Query\",\n",
        "                            }\n",
        "                            )\n",
        "workflow.add_conditional_edges(\"Transform_User_Query\",\n",
        "                decide_to_generate_after_transformation,\n",
        "                {\n",
        "                \"Retriever\":\"Docs_Vector_Retrieve\",\n",
        "                \"query_not_at_all_relevant\":END\n",
        "                }\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "MKML3CbaBw2H"
      },
      "outputs": [],
      "source": [
        "app=workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "bgAKrQmpBw2H",
        "outputId": "47078aa6-b967-40c9-c5ba-efc86b35ed13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb0AAAJbCAIAAAD/ud0RAAAAAXNSR0IArs4c6QAAIABJREFUeJzs3XlcTPv/B/DPLK0z7ftCRSmKlpsoW1K0yFpKRdYbN7vsLnEJcckWkT1rREqkxVYoIdcekW7ap71p9vn9cfrN9WVKpToz9X4+/FEzZ868msyrz/mcM+cQ+Hw+AgAA0GJEvAMAAICYgd4EAIDWgd4EAIDWgd4EAIDWgd4EAIDWgd4EAIDWIeMdAIA2otfyKkuY9TWc+moul8PjcvAO1AJEEiJLEGXlSRR5spK6JEWBhHci0BYEOH4TiJfqcvbH7LpPr+r5fCQhQZBVIFHkyRQFMofFwzvaz5HJBHodt76GS6/h8LiIw+YZmFEMLeSU1CXwjgZaAXoTiA0mnfcwrryhnqukLmlgRtHUl8Y70a8q/Zf56WVdVRmbLEGwc1eVlYPhp3iA3gTiIfte9ZNEmp27qqmtPN5Z2t+7zNr0uHJLeyWrUYp4ZwE/B70JxMCtk8Wa+jIW9gp4B+lYL9Oq897Wu8/VxjsI+AnYnw5EXXRYgaEFtcuXJkKo/1CF/kMUz2z9gncQ8BMw3gQi7dyO/KHjVXuayOIdpPMU5zESTxf7b9DHOwhoEvQmEF2JZ4oNTCl9rOTwDtLZPr+uf/2oZuwcLbyDAOGgN4GI+udBNZfDtxzZTfeTvEyrZrP4Vg7d9McXcTC/CUQRl8NPiy3vtqWJzXU+S6lg1IvBQandEPQmEEUP42hD3FXwToEzO3fVh3HleKcAQkBvApFDr+HV0NjmIzppsPnq1Ssmk4nXw5vRb7A8k8GrLmd3xMrBr4DeBCIn959aqmInnTkhLi5uxowZDQ0NuDz8pxRUJHL/qeuglYM2g94EIufTq3qD/pTOea42DxWxHaodNNIUMDCjfHpZ36FPAdoAzocERAuHxWc2cHsat/8BmwwGY/v27ffv30cIWVpaBgUFZWVlbd++HSHk6OiIENq4caO7u3tJSUl4eHh6enpdXZ2ent7MmTOdnZ0RQlVVVY6OjosXL37//v3du3dNTEzGjx//48PbN7OWgTSRSGio5crAR9dFCfQmEC1V5Wwuu0OOjTtx4kR8fPy8efNUVVXj4+NlZGSGDBni5+cXFRUVFhZGpVJ79uyJEOJwOK9fv/bw8FBUVExNTV2/fn2PHj1MTU2xlRw7dszT0/Pw4cMkEklDQ+PHh7c7Ho9fVc6G3hQp0JtAtNBrObLyHfLfsrCwUEZGZsaMGWQyecKECdiNurq6CCEzMzNFxcbdUDo6OtHR0QQCASE0fvx4R0fHu3fvCnqzf//+gYGBgnX++PB2JytPotdyO2jloG1gfhOIFnoNl9IxYysXFxcGg7Fw4cKPHz82v2ROTs6yZcucnZ0nTpzI5XJpNJrgLhsbm47I1gyKHJleIw7nZO5OoDeByCFLdch/Szs7u71799JoNG9v7y1btnA4wsvoyZMn/v7+LBZr48aNoaGhCgoKPN5/B5/LyMh0RLZmkCXhTSpyYDsdiBYZKqm2oqOOWLSzsxs8ePD58+f37NmjpaU1e/Zs7PZvP20cGRmpq6sbFhZGJpNbWJQd+mHl2gq2Rk+pjls/aAP4UwZEi6xcR03nsVgshBCRSPT19VVTU3v37p2gFsvKygSLVVVV9enTBytNFotFp9O/HW9+58eHtzt6LQfOAy9qYLwJRAtVUYIi1yH/LS9cuHDv3j1XV9eysrKysrJ+/fohhMzNzUkk0q5du8aNG8dkMidPnmxtbR0XFxcbG6ugoHD27Nmamprc3NymRpQ/PrzdY0tTSFRFuPqQaIHxJhAtMlRiA51bnMdo9zXr6uqyWKw9e/Zcu3bN29t72rRp2I3r1q378uXLrl27kpKSEELz58+3tbXduXNnaGjooEGDduzYUV5enpWV1dQ6v3t4+6IVsarK2PIqML4RLXAeOSByniZXshg827Hd/bweCKGspEoOmzfYFV4K0QJ/x4DIMehPzbxJa2aBhoYGFxcXoXfp6uoWFBT8ePuIESM2bdrUfhmFO3DgwOXLl3+8XUpKSugnMnv06HHmzJlmVlhZwjIfrtSuGUE7gPEmEEWJp4p7DaAaWVKF3svn84uKioTeRSAI/y8tIyOjpNThBVRdXV1fL+Tj5CwWS1JS8sfbyWSyurp6U2vLe0N/mV4Fl2kTQdCbQBTVVnBiDhR082vsnNuR7+yvqawppHABvmC/EBBFcspkk4HyOU9r8Q6Cm0//1Ov1o0BpiiboTSCiBrkoZ9+rKs3v2BO1iabKEtajhHI4473Igt4EomvKsh6X9xVwOd1uKulcaP7UlXp4pwBNgvlNINJ4XP7xjXmTF+ooaXSLLdbaCs7Fv/NnBhuQJAh4ZwFNgt4Eoo7PQ+dCv9iNVTMwa/+TGYuUf3PoqRdKfVb1lOiYM5uA9gK9CcTD/Zjysq+MIe6qmvrSeGdpf6X/Mh/GlSuqS9p7qOGdBfwc9CYQG4WfGA/jytV7SGnoSfcyo0pIif2WLJfN//SqviSf8fVjwxB3Vd0+nX2SOtA20JtAzOS9oec8q/38sk7flCJNIcnKkWTlybJUEpcrBv+TiSQio55Dr+HSaznMBt7H7LpeZhQjK7lenXUdOtAuoDeBuCr40FBRzKLXcrDzzjEbmjzbW9tkZGTY2NhgF8xoL5JSBEQgyMqRKPJkZQ1JGGCKKehNAIQbNGhQeno6diJOAL4Fu+0AAKB1oDcBAKB1oDcBEK5///7tO7kJugzoTQCEe/nyJcz+A6GgNwEQTklJCcabQCjoTQCEq6yshPEmEAp6EwDhdHV1YbwJhILeBEC4goICGG8CoaA3ARDO0tISxptAKOhNAIR7/vw5jDeBUNCbAADQOtCbAAinoqIC2+lAKOhNAISj0WiwnQ6Egt4EQDhNTU0YbwKhoDcBEK64uBjGm0Ao6E0AAGgd6E0AhOvbty9spwOhoDcBEO7t27ewnQ6Egt4EAIDWgd4EQDhzc3PYTgdCQW8CINyLFy9gOx0IBb0JAACtA70JgHBwPiTQFOhNAISD8yGBpkBvAgBA60BvAiAcXAcYNAV6EwDh4DrAoCnQmwAA0DrQmwAIB9dPB02B3gRAOLh+OmgK9CYAwsH5kEBToDcBEA7OhwSaAr0JAACtA70JgHA6OjqwnQ6Egt4EQLivX7/CdjoQCnoTAOHg/JugKdCbAAgH598ETYHeBEA4CwsLGG8CoaA3ARAuOzsbxptAKOhNAITT19eH8SYQigB/UQH4louLi4SEBIFAKC0tVVFRIRKJPB6vZ8+e4eHheEcDooKMdwAARAuZTC4sLMS+Li4uRggpKChMmzYN71xAhMB2OgD/w9TU9LtbjIyMbG1tcYoDRBH0JgD/w8vLS0tLS/CtvLw8DDbBd6A3AfgflpaWRkZG2Lw/n883MTEZMmQI3qGAaIHeBOB706dPV1VVxWY2fX198Y4DRA70JgDfs7Cw6NevH0IIBptAKNifDv5HQx237CuTxeDhHQRnriNmVfwr6WY/5eOLOryz4ExSiqSqIykrR8I7iAiB4zdBIw6bnxRV8jW3oYcxhcXs7r0JBKRliPnv6rUMZEZ5q0vJwhYqgt4EjZgNvCv7Cga5qKvrSeOdBYgiWiErPbZ40gIdGSoMPGF+EyCEELqwK9/eSwtKEzRFRVty9HSds9vz8Q4iEqA3AXqVXtPbXF5OSQLvIECkSVNIpnZKz+9W4R0Ef9CbABXnMyjysIcQ/BxVkVycx8A7Bf6gNwFiMXhyKjDYBD8nryLBgX2G0JsAIcSo5/LhvQBagMdD9bVcvFPgD3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTAABaB3oTtFp1ddXIUdbYv3HjR65YGZiR+bBznnrV6oXOrkPodPq3Nx6O2DtylHVRcWEbVvjm7Ssmk9l+ARFC6Hl21revz8pVC16+zG6vMNt3BM+bD9clxhn0JmgjSwvreQGL3d0nl5aVrF6z6Nz5k53wpI6jXJhM5sNH97+98cGD1L59zbQ0tVu7tluJcYELZjAYDe2asdFIe6dZM+cPG+bw9t2rZUHzPnx83y5hZCkUWVlKuyYFrQa9CdrIwsLaa8q0uXMWHI+86DBydOSxg2/evuroJx06dKS0tPS9e8mCW3I+vCss+uro4NyGtbV5pNmSq8s4OIyZ5jd7RdCff+86zOFw4uNjfjEM9qSLFqzY/ffhVuYF7QzOVgt+FYlEWrhgxf0HqbHXo/v1NcO2Nw9HhL1//0ZaWsbOdvj8+Uvl5eSxhV++zD51+sibty8RQubmv82cMa+Pkcm58yevxV6qra0xNDSe4R/wm5VNU88lIyMzxG7Eg7Q79fX1FAoFG2wSCIQRIxyxDeSjkQdyc3OUlJQtLQbOmR2ooqKKPTDhZmzM1Qv5+XlUqpyd7fDZs/7IyEwP27sdITRhkiNCaNXKjc5j3BFCt2/fOHv+RGFhgYqKqpvrRF+fmUQiESE0c/YUA/3e+vq9Y65eYDIZ0RdvUanUlrw+fYxMZGVlS0qLsW+FhryVGPdjmL37dty7nxK0bH344T1fv/67a2f4zl2bS0qKzczM9+89hq0t9vrlS9FR5eWlmpraoxycvaZMQwh5erkMsrFbt3YLtkx29tOlywO2bQ0bPHhoUXFhePjup88yJCWl+hiZzJr1h4lxv1/7/XdH0JugHSgqKhno93779hVCKC/v0/Kgefr6vVeu2FhdVXni5OHS0uK/dx1CCD3Jerxm7eLevYzmBSzh8XiPHt3ncjhPn2UejTwwapTzoIF2mU8eNvzv3OWPHEe5pKQmPnx4z8nJFSF0/0GqhflvKiqqT59lrl6zyMnRdeIEr9qa6isx55cFzYs4FCUtLX3yVMSp00ftRzh6TvatrKp48uQRWUJikM2QKZ5+l6Kjtm0No1Couro9EUKJifHbQ4NHjXKePeuPN29eHj9xCCE0zW829tRPnjxiMBkhW/bQG+gtLE1sOphOp2uoayKEmgopNAxCqL6+7tiJ8CWLVzMYDVaWA5cvW3/06H7Bmk+eOhJ9OWrSRG89vV7//pt38dLpgq/5a1dvHu3kdiPhKp1Ol5WVRQglJSdoaGja2NjRaOULF83S0emxIDCIQCDcvn1j8ZI5h8PPGBj0butvvpuC3gTtQ1FRKefDO4RQ1NljRCIxdMcBOaocQkhOTj5k+4YXL56Zm1sdOLhLU1N7/77jkpKSCKEJ4z0RQjcSriGEJo6fYmo6AKvC5llbD1ZQULxzL8nJyfXz59z8/DxPD1+E0P4DO93HTlq0cKVgMf+ZHk+yHpkYm0adPe7k5Lp29WbsLm+v6dgX2tq6CKG+fc0UFBSxDeHI4wf797dYv3YLQmj4MIfa2poLF09NnjQVKyASmfznuhAZGZmWvCA0Wnl5eVlJSdGp00eIRKKb28RmQg4bOvK7MBgWixW0bH3fvmbYtwOtB0dHRzUwGhBC5eVlZ88dX79u64jho7B7VVTU9oRtWxAY5D520pWY8w8epI4ZM5bJZN5/kOI1ZTqRSDwTFamkqPz3zkNkMhkh5OTo6jd9QnzC1YWBQa35VQPoTdBOqqurpKWlEULZL55aWg7EShMhNHCgLULofc4bdQ3N/Py8ObMDsdIUGDxoqJycfMi2PxcuWDF48NCfPhGZTLYf4ZhwM7auru7e/RQymTxsmENxcdGXL5+/fv03/sbVbxcuLS2pr6/jcrnj3T1+uuaCgvzy8jJsU1cQPuFmbMHX/D5GJliptbA0EUJhe7djm95KSsrr1m7pY2TSTMimViItLS0oze88fZrB4XC2hqzfGrIeuwWbAC0vK+3Vy7B/f4vklJtjxoxNf3iPwWC4uoxHCGVkpJeWlbiOHSZYCZvNLmv62UFToDdBO+Dz+cUlRfr6vbBNS0UFJcFdcnLy2OCoqrICIaSupvHdY1VUVA/sO37w0O4165aYmZlvWL9NTU29+adzHOUSe/1yevrdB2mpv/02SEFeofDrvwgh/+m/Dx/m8O2Sysqq1+MuI4TUfnjeH9XV1yGEFBWVvw9fVor1pox0S0sTITTDP8DUdMDefTuIROLQIfYIocpKWlMhm1qJjIxsU3fRKsoRQiFbw757SbFxq7vbpO2hwTRaeVJywtAh9srKKgihikqare2w3+cs/HZ5CqWlEw5AAHoTtIOHD+/X1FSbD7BCCKmqqtfUVAvuqqysQAhRqXLY+7Oikvbjw3v21N+xbd+z5082bAzaERq8a2d4809nZmaupal94dLpvLxP3lOmY+tHCDGZjJ499b9bGLuropKmri68OgU7x7ECqq7+7zq3WHi5/9+p1Sq9extZ/zZoxfI/Fy+de/rM0TmzA5sJ+WOYnxKkErq24cNH7T+4K+bqhSdPHu0MPSh4SHV1VTPPDloIjkMCv6q6uurosQNSUlKuLhMQQqamA7JfPGUwGq8We/9+CkKof3+LHj301NTUE2/Hczgc7C4+n8/j8bBZPISQleXAwYOHYZOkPzVqlHNe3idJSUk7uxEIIV3dnhoamjdvXW9oaDz+kcPhsNls7DhThFBCwjXBYwUBsPFjeXkZ9q2KiqqmhlZmZrpgyXv3kqWlpQ0Njdv84gwYYDl+nMeFi6dzPrxrJuSPYX7K0nIggUC4eu2i4BbBahFCUlJSTk6u5y+c0tHpgb0CCCErK5tXr168z3kr9CGg5UjBwcF4ZwA4e5tZq6EnQ1Vs6aWAmUzGhYunORx2SUnR/fspYft2lJWVrFj+p7m5FUJIX6/XlZjz2S+eSkhIPs5IO3YifEB/S//pcwkEgpKSyvW4KxkZaWw2+33O2/0HdkpJSrHYrCVL53I4nNxPH+LjY0yM+7Vk75CKsuq12OghdiNGj3ZDCBEIBA0NrYSE2IeP7vP56M2bl/v2h7I57H79+isoKNJoZfE3rubl5dbT67OyHm/fsXHIEHs5qpy0jGzs9ei8L58IiPDm7Utj435yVPmL0VFlZSVsNjvm6oXklJu+PrMGWg9GCMVej1ZSVMYOeGpecXFh4u14h5GjsZFd//6WSck3nmZluLpO0NLSERoSIfRjmIyM9C9fPn8734rtHOdwOK4u4+XlFWpra2/fvpHz4S2TyXyckR6y/U9Ly4GCQ6801DWvxUb7+c7C1o8Q6tXLKCk5ISkpgcvl/lvw5ezZ4/cepDiMHNPC3ztCiF7L/fqh3sxOoeUP6ZKgN0Ebe7O0tOT1m39Ky0osLaxXrtg4yMYOu1deXqG/meWTrEdx8Vfe57wdaT96RdAGKSkphFCvXoaGhn1evHialJyQk/NWR6fH0KEjpSSlcnNz7ty5/exZprm51dIla1sy46aoqPTw4b1x4zywSVWEkF5PAxPjfv/88/x20o2371717mXk5OSGlcjgQUMlJSUfPbqfeuf214L8gQNtLS2sKRSKvJy8mprG3btJjx49qK2tGTNmrKFhHyUl5dQ7t2/eul5VWeHjM9PPdxaBQPiV3pSUlOyhqxd9+SyZTB7nPrmpkD+Gab43sd1WsrKUR48epN5JLPiaP8RuhJ3tcMGeK0VFpdevX8ya9Qf24mNPMcRuxJf8z0lJN55kPaJQqG6uEwQvYEtAb2IILZ9PAV1VzIGv/Ycpa+q3YqcH6J7KC5kZN0q9g3rgHQRnsF8IiJyjkQewneDfkZdTOBsVi0ei79XV1U31HSv0roDfF491m9jpiUCngt4EImfKlGljx0768XYiQVR2Y8rKyh6JOCf0Lnm57r4N2x1AbwKRoyCvoCAv0u1DJBLbcPol0GWIyh9wAAAQF9CbAADQOtCbAADQOtCbAADQOtCbAADQOtCbAADQOtCbAADQOtCbAADQOtCbAADQOtCbAADQOtCbACmokOGsWKAl+AgpaUi2YMEuDnoTIFk5cnkBA+8UQAzQChjSslAa0JsAIf1+lJpyFt4pgBioLGEamFLwToE/6E2AtHpJq2hLPopv6ZVtQPeUeaucqkjqadLkJTa7DzjfO2j0LLWqJJ+paSCrqiNFIhHwjgNEBY+LygsZZQUNcgrkwW7KLXhE1we9Cf6T/7Yh53lNQz2vslgkNts5HHZtba2SErxXfwmNRuPzeT++0396nXqMiraUpBTB0ELOwAxGmo2gN4GI+uuvv3Jzc9evX29oaIh3FvF27ty548ePV1VVfXsjkUjMzMzEL5R4g/lNIHKuXbtmbW3dv3//kydPQmn+Oh8fHw8PDyr1f64Sqqqqil8isQfXAQYiJDc3d+nSpVwuNyoqysTEBO84XYe1tXVZWdnHjx+5XC5CiM/n379/397evqqqavDgwXinEz9wfSEgKnbt2vXp06cVK1aYmZnhnaULWrFiRU1NTVJSEofDkZCQQAjdvn07JSUFIZSTk3P//n0PDw9FRUW8Y4oH2E4H+EtJSRk6dKiurm54eDiUZsf566+/hgwZQiAQlJWVEUKSkpIuLi4IIT09PTabfeTIEYTQmzdv8I4pBmC/EMBTSUnJpk2bevfuHRgYKC0tjXecbsHPzy8qKqqpe2/durV+/XqYJ2ke9CbATWRkZExMzMaNGwcNGoR3FvA/iouLNTU1165d27t371mzZhEIcDzv/4DtdICDV69eTZ06lcPhJCQkQGmKIE1NTYTQsmXLmExmfX09k8lMS0vDO5QIgfEm6GyhoaFv3rzZsmWLrq4u3llAi3C53OXLlyOEwsLC2Gw2tlupO4PeBJ0nMzPzyJEjTk5OXl5eeGcBrUaj0VRUVC5fvvzy5ctly5YpKCjgnQg30Jugk2zbti0/Pz80NFROTg7vLOCXxMfHKysr29nZZWVlWVtb4x0HBzC/CTrcixcvHB0djYyMDh06BKXZBYwdO9bOzg4hlJ6ePmHCBA6Hg3eizgbjTdCx9u/fX1lZuWjRIjimuksqKChQV1dvaGi4efOmt7c33nE6CYw3QUcpLy/39vaWk5PbsGEDlGZXpaurKykpKS8vX1BQEBgYiHecTgLjTdAhEhMT9+zZs3//fiMjI7yzgE5Cp9NlZWWvXLlCJpPHjx+Pd5wOBONN0P62bNny8ePHW7duQWl2K7Kystjs54sXLx4/fox3nA4E403Qnurq6mbNmuXj4zNhwgS8swA8YWPP1atXL1myBDuKviuB8SZoN8+fP3dzc9u2bRuUJsDGnl5eXtu3b8c7S/uD8SZoH/Hx8bdv3963bx/eQYAoOn/+vIGBQZc51yeMN0E7OHz4cFZWFpQmaMqkSZPOnDlTWFiId5D2AeNN8KsSEhJyc3MXLlyIdxAg6qqqqurq6iorK/v37493ll8C403wS4KDg0tKSqA0QUsoKirq6Oj8/fff2dnZeGf5JTDeBG23efNmc3Pzrn2kHugIz549s7KywjtF28F4E7TRvn37bGxsoDRBG2Cl6eHhwWAw8M7SFtCboC3Onj3L4XCcnZ3xDgLEWEREREREBN4p2gK200GrPX/+/ODBg5GRkXgHAV1BaWmpgoKClJQU3kFaAcaboHUYDEZkZCSUJmgv6urqgYGB4rWnCHoTtE5wcPDEiRPxTgG6lMjISDKZXFtbi3eQloLeBK2Qnp5Op9MdHR3xDgK6GjMzs9zc3IaGBryDtAj0JmiFc+fOrV+/Hu8UoGsyMzMbOXIk3ilaBHoTtFRSUpKcnJy6ujreQUDXRCaTk5OTxWKiE3oTtNSVK1dmzpyJdwrQlVGpVGNjYzqdjneQn4DeBC2Sk5NTXV1tbGyMdxDQxcnIyMyaNevDhw94B2kO9CZokeTkZNgdBDrHwYMH09PT8U7RHOhN0CKfP392cHDAOwXoFlRUVGbMmIF3iuZAb4Kfq6+vz8jIMDAwwDsI6C44HM7q1avxTtEk6E3wc2/evIGPooPORCaTe/Tocfz4cbyDCEfGOwAQA1++fCEQCHinAN1LYGAgjUbDO4VwMN4EP1dXV2doaIh3CtDtyMrKMplMvFMIAb0Jfq6oqAjGm6Dz5eXlzZ49G+8UQkBvgp+TlZVVVlbGOwXodvr27WtsbFxQUIB3kO/B+TdBk5ycnIhEIp/Pp9PpkpKSEhISfD6fSqXGxMTgHQ0APMF4EzSJSqXSaLSKigoGg1FTU0Oj0crLy/v27Yt3LtCN0On0u3fv4p3ie9CboEkuLi7f3aKtre3r64tTHNAdycrK7tu378uXL3gH+R/Qm6BJ3t7ePXv2FHzL5/MHDBjQr18/XEOBbmfhwoWidkAS9CZokry8vLOzs2BPupaWFgw2QecbOXKkqF00GHoTNMfHx0dXVxf72tzc3NTUFO9EoNthsVhRUVF4p/gf0JugOVQqFfuEpaampo+PD95xQHckKSl5+fJlkToaSSw/Z1lN4yA4fKqzjB0zJfnmw379+ulq9KkuZ+Mdp7uQkCLKypHwTiEqFixYIFIfHBKn4zfZTP69K2Ufs2t1jSi0IhF6EQFodzJUUl0Vu99ghcGu8IkDkSM2vcmg804Gf3aapqOsKUWWhM/8ga6PXsv98rq2rIDhNlsT7yw4y8vLe/funeiclEs85jf5fBS5/pPvut7qPaWhNEE3IStH6jtYUbu3bNyRIryz4IzH4x07dgzvFP8Rj958cLV81FRtvFMAgANDS3l5FcmP2XV4B8GTvr6+l5cX3in+Ix69+eVNvbyKBN4pAMCHpAyxJJ+Bdwo8EYlEDw8PvFP8Rwx6k89FMnJk6E3QbSlrSTEbeHinwFlkZKToHIokBr2JCKjkSwPeIQDADY/Nr6/m4p0CZ+/evROdiwOL5fGbAIDuZubMmVQqFe8UjaA3AQBiQKQ+4ysO2+kAgG7v4cOHt27dwjtFI+hNAIAYKCsry8zMxDtFI9hOBwCIAWtraw0NDbxTNILeBACIAR0dHR0dHbxTNILtdACAGCgqKrp8+TLeKRpBbwIAxEBVVdW1a9fwTtEIehMAIAZ0dHT8/f3xTtEIehMAIAbk5eWdnJzwTtEIehMAIAbqPul+AAAgAElEQVSqqqrCwsLwTtGoK/dmSUlx2N7tU33cncYMnjDJceu2P0tLS359tVtC1k+fMRn7OuFm7IRJjiUlxb++2h91UP5fV1xcVFRc2IYH3ki4NnKUNY1W3swyd+8ljxxlPXKU9SgnG48pzltC1n/58vkXwuKmrq4u58M7vFN0HSwWKzExEe8Ujbpsb75+/c+cud4JN2NNTEy9vaZbWljfvZuU9fRx+z6LpKQUhUIlEtv/Zeyc/G3wtbDAx2/c+/dvOvRZ3Fwn/D534fBhDllZj+f9Me15dlaHPl1HmPO7982bsXin6DoUFBSCgoLwTtGoax6/WVdXt3HTSglJyX17jxkY9MZuLCjI19QUfvJjPp8vuEp4qziOcnYc1epz938tLNDW0mnmGVubv301/2pwOZxOuLbKmNFj+/e3QAj5T/990ZI5f21Ze/ZMrIyMTEc/bztisVh4R+hSpKSkRo0ahXeKRl2zNxMT42i08j/XhwhKByGkq9tT8PXefTvu3U8JWrY+/PCer1//3bUzvIeu3rET4RkZ6fX1dT166PlMnfltIabeuX3q9JGSkiJ9vV48XuOZELeHBicmxiOEkhIfk8nky1fOpd657enhe+zYQVpFuZGRSdCy9T176iOE2Gz28ROHklNuNjTQBwywysl5O81vzvhxTZ6H9af5EUJFxYXh4bufPsuQlJTqY2Qya9YfJsb9EELu4+2XLF6TlnbncUYahUJ1HzvZf/pc7CEMBiPy2MGU1FssFrOHrt6UKdMcRo7GNo03bV7916ZdF6PPvHv3eqq3v5/v7NNnjqamJpaWlaioqI52cpvhH0AikYqKC/1neiCENm1evQmhMWPGrl4Z3EwYhNCHj+/3H9j5/v0bFWXVHj30WvurVFBQnDtnwZ8bgu7eS3JxHocQevP21eGIsPfv30hLy9jZDp8/f6m8nDy2cMLN2JirF/Lz86hUOTvb4bNn/SEnJ+80ZvDcOQt8ps7Allmzbkl1dVX4gZMfPr5fsnTun+tCjh47kJ+fp6Gu6es7q6KCdj3ucl1draXlwKBl6xUVlbBHxV6/fCk6qry8VFNTe5SDs9eUaVJSUh8+vl+4aNb2kH1HIvfn5uZoaGgFzF00ZMgIhJC3z9jKyoprsdHXYqM1NDQvnItnMBhh+7Y/fHgfITRggOWCP4I0NbVa+2p0Z3Q6fe/evWvWrME7COqy2+mZWY9kZGSGD3NoZpn6+rpjJ8KXLF791+ZdVpYDOVzOu3evx4/zmB+wRF5eYWvI+rfvXmNLJqfc+mvLWhVl1YULVgwcaJv7qfEkgJMmejs5uX67zrdvX126dGb58vWbN+0qKy3ZtmMjdvvhI3svXznnMdln6ZK1OTlvmUwGVgFtzk+jlS9cNKumtnpBYFDA74vYbPbiJXM+f87F7t2+Y6OhoXHYnqNOjq4nT0U8fpyGXaFl3fqljx7d9/WZuXTJWkND47+2rE34ZkNy7/4dY10nhu444D52MolEevo0w9Zu+Px5S60sbaLOHr8Scx4hpKKsum7tFoTQzBnz9oVF+vnMaj5Mfn7e0mW/08rL5s5Z4Onp17b5Pgtza+y1RQjl5X1aHjSPzWavXLHRf9rctLQ7mzatwhY7eSpi566/eujqLV+6boqnX1HRV7LET851TafTw/Ztnzt7wY7t+yWlpEJ3bs7ITP9zXciypeuePcs8eGj3/6/5yJGj+xxGjl4RtMF+hOPFS6f/3rMVu4vJZG76a7XHZJ+w3Uc0NbS2hKyrrq5CCAVvDJWTkx82dOS+sMjgjaEIoXPnTyQmxntM9gn4fVFNTbV4jZ1FAYfDuX37Nt4pGnXN8WZxcWEPXT0y+b+fTrBHRVlZBbudxWIFLVvft68Zdru2ls7J49HY9qmLy/iJkx3T0+/2NTFlMpkHDu4aMMByZ+hBEomEEPr69d+PuTkIoT5GJvp6vb576q1b9igrqyCEJk3yDj+0p7qmmkqhxsfHuLlO8JoyDdsK3hqy/uWr7N+sbNqc/0xUpJKi8t87D2HLODm6+k2fEJ9wdWFgEELI1WW8r89MhJBh7z43Eq5lZj0aPHjo/Qep/7x8fv5snKqqGjbD0NBAvxJz3tVlPLbmiRO8xowZK3jG8IOnBFvrhUUF9x+kTvH0k5SU7GNkghDq2VMf245GCDUT5vCRvUQC8eCBk9jAjUgkhu3d3trfJpVKJZPJNTXVCKGos8eIRGLojgNyVDmEkJycfMj2DS9ePNPW1o06e9zJyXXt6s3Yo7y9pmNvtuZXPi9gyeDBQxFCUzz9doRuWrp4jYFBbzNk/vRpRkZmOkKovLzs7Lnj69dtHTG8cSNRRUVtT9i2BYGNc20LF6zAhu1z5iwImOf34p9nw4c5mBj3I5PJKiqqglepqLhQRkbGZ+oMMpns5jqhtS8CkJWVXbVqFd4pGnXN3uTz+d/tq/Ga6oZ9cerEZWzbWVpaWlCamI+5OSdPRWB7PLhcbkUFDSH08lV2dXWVx2QfrDQRQsT//0IoaenGcYSGhhZCiFZexuVwWCyWjk4P7Hbsi9raml/Jn5GRXlpW4jp2mGABNptd9v/dKshAIpHU1NRp5WUIoceP0zgcjo/ff+NcLpdLofx3Ilir/+3xysqK02eOPsl6jEXFekqopsIwGIwnTx6NG+ch2Nr99i9By9HpdA6HIyUtjRDKfvHU0nKgIMzAgbYIofc5b4qKv3K53PHurb4EjZSkFPaFhIQkQkhCUhL7Vk1NHRs5Pn2aweFwtoas3xqyHrsLm94tLyvFvpX53994eXmZ0CdyHOWSknJr1eqFgX8s79XLsPUvQ3dHJpNF5zrAXbM3VVXUcj99+Hb/RsiWPRmZ6bHX//t8q4yM7LcPefb8yarVCy0trFeu2EiRpWwIXsHj8xBCpaXFCKE27JCRIEsghLg8roKCIpVCffky29PDV7C92buX0a/kr6ik2doO+33Owm8f9W0JCpBJZC6PixCqrKSpqKju3nX423tJ3xSZ7DcvSEUF7fd5vjIysrNmztfW1j1+PPzfgi9NpW0qDK2inMPhaP3yvqyioq8IIU0NLWx2RVFBSXCXnJw8VlXYuFJNrd3Ol0MgELB+pFWUI4RCtoap/+/KtbV1P+flfnsL9hvn8YRf0GKQjd22kL2HI8Jmz/V2c52wZPHqtv0V6baYTGZERMSiRYvwDoK6bG8OGGD1PDsr88mjQTZ22C22tsNKy5o7+PHMmUhtbd2QrWHY/2bBIAJ7l1ZVVbY5DIlEmjp1xtHIA1u2rlNVVY+9Hj150tTm95D8NL+cnHx1dRU2cG4hOTn5qqpKDQ0tKSmpny58Pe5KZWXFwf0nNTQ0EULq6prN9GZTYerr67Fxa8tDCnUrMQ57TRBCqqrq2AY7Bls5lSpHpcphDa6u/j/t1rbDJL4l9/87nVr1amO+O/BgkI3dQOvBV2LOhx/ao6GhNc1v9i9m61bYbHZCQoKI9GbX3C/k6jJeWlp6T1hIYdFXwY0cNruZh1TXVBn27iOY+qQ30LH95r179yESickpN38lz4TxUwZaD66srKirq123dsuCwOW/mN/KyubVqxfvc94Kbmlo+Mml66ysbLhc7vW4/0bczTykpqZKUVEJK03sxRFUgJSUNDb/8NMwFApFR6fH3XvJ7GZf+ea9e/8m/kaMvn4vK8uBCCFT0wHZL54yGI0Xxb1/PwUh1L+/haWFNUIoIeG/8z5gI1ASiSQnJ19Oa0zL5/OxDYiWs7QcSCAQrl67+N1P91My0jLfHuGPHZZEJBI9PXxVVdU+wCHxrSQlJTV7tqj8pema4011dY3ly9aHbPtz9hyvYcMcNDW0CgsL7t1PIZFIggms71hYWCcmxiXcjJWXU4i+cra2tibvcy6fz9fQ0HRxHncj4RqLybSxsaPRyjMy0pSUVFqV56+ta+XlFWxthyOECIhQUlIsqKS25fef/vvjx2krVgZO8fRTUlLOzHzI5XG3bP67mXU6ObrGxcccjthbVFzYx8jk48ectPQ7J49flpaWFvpqXL126fiJQ6am5g8epGZkpPN4vOrqKgUFRXV1DW0tnUuXo6RlZGpqqidN9G4mjP/030O2/blg4Uxn53FEIhHbKd8S1+MuP32WUfD13/v3U2RlKevXbsVGjn4+s1JTE1etWeg+dnJpafGp00csLawtzH8jEAhj3SbGxcfU1FQPHGhbXV0VF3dl9+4ILU1tm4G2SbdvWFkOVFZSuRQdlZ+fZ2Rk0sIYCCFdnR6TJnpfiTm/dv3SoUPsabTya7GXtoXs7fOzlfTvb5mSeuvc+ZNycvKm/QZkPnmY/vCek6MrjVZWXl5m/P/HaYEWkpCQ8PT0xDtFo67Zm9j+Yg11zbPnTzx+9KCB0aChrjlm9NiJE7yamm6bNWN+Ba18/4GdcnLyY90mTfHw2x0W8jw7y8py4MIFKyQlJZNTbmU9fWxmZtG7dx9sl1HLWVkOPHkqIiW18VNiJBJpZdCG0aPd2pxfR1v3wL7jhyLCzp47TiAQjIxMJk7waj6DhITEzh0Hj0buT01NjI+P0dXtOc7do6kptuHDHKZPm3P12qVr1y7Z2g0/eODktu0brl67OMM/gEAgrF8fErpz04GDu9TVNUfaj24mjJOjS11d7aVLZyKO7NXX69WvX/9//21ye/9bySm3pKSk1NU1x7l7eHtNx44BwA5iDd1+4Ejk/tCdm2RkZJ0cXecFLMEqdemSNZqa2vHxMekP76mpqg8caEsmkRFCgX8sZzKZ23dspFCo49w9GEzGt1v6LRH4xzJ1dY2rVy8+efJIRUV12NCRaqrqP31UwO+LKirKz0RFKioo/fHHMm1tXTaLdejwHgqFOmmSN3ZwBWg5BoOxe/futWvX4h0EIYQInfDZj1/E56HwoI/TN4rxLkgulyvYHV9TW7N6zSIymbwvLBLvXEA8FLyv/5hd4/57tz5Ovq6ubuzYsXfv3sU7COrK402R8vfurbm5Oba2wxUVlfL/zfv06YOb28RFS+Z8/vzxx4Xt7EasWbUJj5idpzv/7KBtpKWlt23bhneKRtCbncHGxq60tPhKzDk2m62lpTN92lxPD9/q6io2R8gOE8Gu/C5sw/pt3fZnB21DJpNtbW3xTtEIerMz2I9wtB/h+N2Ngjm7bqg7/+ygbRoaGtasWSMip+DsmschAQC6GC6Xm52djXeKRtCbAAAxICMjEx4ejneKRtCbAAAxQCKR+vUTlYNeoTcBAGKATqfPmTMH7xSNoDcBAGKAx+N9/Cjk2DVcQG8CAMSArKzs0aNH8U7RCHoTACAGiESikVFzZ1/sTNCbAAAxQKfTZ86ciXeKRtCbAAAxwOPxPn/+jHeKRtCbAAAxAPObraZlINuCpQDomohkAlWxu38kGuY3W4dARPQ6dnUZC+8gAOCDVsiUpojBW7VDNTQ0BAQE4J2ikXj8MgxMqdVlbb/WAgBijdXA1dLv7meK4nK579+/xztFI/HozSHjVNKuFTfU8fAOAkBne3GvksXk6pt296kqGRmZ/fv3452ikRic7x3DZaOj63OHTdRUVJeUV5HAOw4AHYyPaEXM/Dd1fMQbMRlOuydaxKY3MQ/jaLn/1FGVJEq/tOiagl0Vl8sjEgm/fpFb0cTlcgkEIpHYNX+6FqIqSZAlCKaDFcyGyOOdRSQwGIwNGzaEhobiHQSJX29i2Cw+Er/U7SYpKenTp0+iM0fe7hgMxpo1azZu3KioqIh3FtyQJbvqn8U2EqnrC4llb3Zb0dHRnp6elZWVSkpKeGfpcHV1dV+/fq2trbW2tsY7C8Afh8NJT08fMWIE3kGQ2OwXAgihLVu21NfXI4S6Q2kihKhUqqGhYWRk5JMnT/DOAvBHJpNFpDShN8VDVlYWQsjPz2/GjBl4Z+lUJBLp8OHD8vLyCKFXr17hHQfgicFgbN++He8UjaA3RRqPx5sxY0ZtbS1CSF9fH+84+DA2NkYInT59OioqCu8sADccDufWrVt4p2gE85uiKy8vT0FB4evXr2ZmZnhnEQnJycmOjo55eXnd9k9Id8Zms69du+bp6Yl3EAS9KaJ4PF5AQMDixYuhMX904MABJSUlX19fvIOA7gu200VOcXFxRUXF/PnzoTSFWrBggYqKCvZC4Z0FdB4mk3ngwAG8UzSC3hQhHA7njz/+aGhoUFVVtbKywjuO6HJ2dkYIxcXFRURE4J0FdBI2m3358mW8UzSC3hQh165d8/f3NzAwwDuIeJg7dy6BQKiqquJyuXhnAR1OSkpq2bJleKdoBPObIuHQoUPz58/HO4VY4nA4VVVV6enp48ePxzsL6C5gvIk/BwcHGxsbvFOIKzKZrKqq+uLFi2vXruGdBXQgBoOxc+dOvFM0gvEmnjIyMgYNGsThcMjk7n4271/39u3bvn37fvr0qVevXnhnAe1PpD6fDuNNfHC5XA8PDwqFgo2Y8I7TFfTt2xchtHv37rS0NLyzgPYnLS29atUqvFM0gvEmDkpLS4lEYl1dHRy/3RHi4uLc3d3xTgG6MhhvdrbVq1fT6XRVVVUozQ6CleaqVauqq6vxzgLaDXw+vftKTEx0dHSExuwEa9asEZ3DVsCvg8+nd0dXrlyZPHkyi8WSlJTEO0v38vTp099++w3vFOBXcTic1NTU0aNH4x0EwXizk1y4cCEvLw8hBKXZ+eh0+ubNm/FOAX4VmUwWkdKE3uxwdXV1CCETE5Ply5fjnaWbGjZsmLm5OZ1OxzsI+CUMBiMkJATvFI2gNzvQP//8s3HjRoSQhYUF3lm6tfHjx0tJSYnOp5tBG3A4nNu3b+OdohH0ZgdKSEj4+++/8U4BEHbqeDc3N7hUkfiSlpZeu3Yt3ikawX6hDhETEzNp0iS8UwAhuFxubW1td75SJvh1MN5sfwsWLDAyMsI7BRCORCLFxcXl5+fjHQS0jkgdvyken/DjcDhica4wBoMhLS29bNkyHR0dJpPZwkdJSUl1cC7wP6ZNmzZ37tyjR4/iHUS88fl8FovVaU/HYDAKCwtb/rZqFyQSSejHoMVjO72urk7094dyuVwmkykrK9vaByorK8NH1IHYYbPZlZWVnfmMTCazkwcZFAoFO4nEd2A7vd3U19e3oTQBjhYuXFhYWIh3CtBSorNlBr3ZDjgcDkIIu8w3ECP79+8/ffo0dowtEH319fV4R2gE2+m/Cptw+ZW/hLCdDsRRJ2+n8/n8iooK7JJ8nQa20zsKh8MRnc0H0AZVVVUzZ87EOwX4CQKBQKVS8U7RCMab7endu3cGBgatrVEYb+Luy5cvN2/enDdvHt5BxMmP480XL16sWbMG+5pKpfbp02fq1KmmpqbNr4fL5b579+6ni+3evfvLly979+795eCtAOPNdsZkMr+bF0tKSlq2bBmDwcAvFGgjPT09KM32Mnz48OnTpw8ZMuT9+/dr1qzJzc1tfvm9e/e25MLosrKyorNh10WGOUVFRZqamgQCoUOfhc/nY0/B4/GIROJ3Ww2deSwb6AinTp3S09Ozt7fHO4h4GzFihK2tLULIzc1t0aJFN2/eXLBgQTPL//SNg73vAgICKioq2jus8Of66WLi2ptsNvvMmTN37txpaGgwMzP7+PHj1KlT3dzcsI2FkydPfv78WVFR0dzc3N/fX1lZGSHk6ekZGBj46NGjzMxMCoXi6urq4+ODrY3BYJw6deru3bssFktXV3fSpEkjRoxACD148GDbtm1//vnnlStXcnJyPDw8XFxcTp8+/eTJEzqdrqOj4+Xlhb3NkpKSDh48iBCaOnUqQmjp0qVOTk7NhAEiyN/ff8WKFYaGhrq6unhn6QoMDQ1lZGTKysqwb2/cuBETE0Oj0TQ0NOzt7SdNmiQlJbV79+779+8jhFxdXRFCx48f19TUDA8PT0tLW7RoUWRkZGFhYUhISFhYWGlpqYmJye7du5taG0Jo+vTpv/3228qVK7Fl/vnnn9WrVwcHB9vY2BQXFx89evT58+dSUlK9e/eePn16nz59EEI/PldLzsIjrr15/PjxGzdu+Pv7q6ioREZGMplMrKeys7M3bNjg4OAwbty4mpqa2NjYNWvW7N27V1paGpsi8fX19fDwePDgQVRUlKGhoY2NDY/H27RpU0lJiZeXl6Ki4osXL3bs2MFgMMaMGYM9V3h4uL+//7Rp03R0dNhs9tu3b93c3OTl5R8+fBgaGqqlpWVsbGxtbT1p0qSYmJjg4GAKhaKtrf3TMEAEic6VZruA6urqhoYGNTU1hNDZs2djYmLGjRvXs2fPgoKCy5cvf/36NSgoyMvLq6ysrLi4OCgoCJvrxx5Lp9NPnz4dGBjIYDDMzc0XLVp04sQJIrFxXrGptTk4OCQmJjY0NMjIyCCE7ty5o66ubm1tXVFRERQUpK2tHRAQQCAQUlNTV65cGRYWhl154bvnasmPJpa9yeVyb968OWbMmMmTJ2O3hIaGvnnzxsLC4vDhwy4uLvPnz8dut7KyCggIePbsmZ2dHUJo9OjRXl5eCKFevXolJiY+e/bMxsYmPT399evXJ06cwA5xsLe3ZzAYsbGxgt50d3d3dHTEvmaxWEePHsVG8qNHj/bx8Xn06JGxsbGSkpKWlhZCyNjYWEFBAVu4+TBANL158+bTp09jx47FO4i4qqiooNFopaWlZ8+eJRKJzs7ONBrt4sWLK1euHDp0KLaMiorKgQMHAgICdHR0FBQUqqqqvtsvxGKxFi1aZGJign1rZWUVExOD7RxuZm0uLi6xsbHp6emOjo5MJjMtLW3y5MlEIvH8+fOKioohISHYDlgHB4c5c+YkJiYGBAT8+FwtIZa9WVNTw2KxsDEdQggrrNra2pKSkvz8/MLCwu+uQyLYUhAM9EgkkoqKCo1GQwg9efKEw+HMmjVLsDyXy/12J5pg3M7n8yUlJXNzc6Oioj58+IAtWVVVJTTkT8MA0dSvX7+TJ0/KyMiMGjUK7yxi6eDBg9iclaKiIjbvkZyczOFwdu7cKRjOY4fx0Gg0OTk5oSuRkpL6sciwRz1//ryptenr65uamt65c8fR0fHx48dMJhMb/WRlZZWVlQmGWdhEn+CdKPS5mieWvSkvL0+hUF6/fj1x4kSE0Pv37xFCBgYG2FERPj4+Q4YM+XZ5oVOKZDIZO1dIZWWlsrLytm3bvrtX8DU25mcwGBwO5+PHjxs2bBgwYMDSpUtlZWW3bNnC4/GEhmxVGCBSQkNDm/pzCH7Kz8+vb9++4eHhRCIR20GE7c8JDg5WVVX9dklsxCMU9qb7Drad1/zaXFxcdu/eXVFRcefOHVtbWyUlJezNaGNj891RuoKxkdDnap5Y9iaJRPL09Dx58uSOHTtUVVVv3Lgxfvx4XV3dgoIC7AihHj16tHxtVCq1urpaXV29maMc+Hw+n8+nUqkXLlzQ0tIKDg7GivXHmUrB8bDY3vbWhgEigs/nf/nyRU9PD+8g4sfAwMDS0nLx4sUrV648d+7cjBkzBIPKpt4LLTyKHJvfbH5tQ4YMiYiIuH79+tOnT7ds2YLdSKVSa2pq2vGdKK7Hb7q7u1tZWVVVVdXV1a1YsQKbp9DR0VFXV09KSmpoaMAW43A4bDa7+VVZWFhwudyEhATBLYKHCxAIBOyPUnV1da9evbDSZLFYDQ0NgvEm1qGCQyXaFgaICCUlpc2bN2dnZ+MdRFyZmZm5ublduXLl48eP5ubmBALh+vXrgnu/fYtJS0tXVlY2td32LWyZ5tcmJSU1cuTI6OhobW1twU4eCwuLN2/eYHNrPz6kDUjBwcG/8vjOwWKxvmucrVu3UiiUESNGaGpqSkhISEpKUigUAoGgrq6emJiYkZGBEHr79u3hw4c5HA42eREdHW1oaGhlZYWt4ebNm7KysiNGjNDT03v+/HlycnJNTU1lZWVycvLhw4ednZ3JZHJ+fn5aWtqYMWOkpaUlJCQQQgUFBQ8ePFBUVCwrKwsPD8fOpuPi4oIV640bN/Lz8wkEwrt37/r06dNMmG/JyMgIdhQC0TF8+PDs7Oy+ffviHURE8Xi87z7lUVJSkpKSMmLECGxkZ2Zmlpqa+vz588mTJ9Pp9JSUlA8fPjCZzKysrF27dpmbm2NzVnV1dffu3aPRaHV1daWlpbq6uk+ePMnPz/92OhIhlJqaymQynZ2d5eTk6urqmlobQkhNTS0+Pt7b21vwXjMwMLhz505qaiqXyy0oKLh48WJaWhp2rKHQ5xKQlJQUeg1asdxOx/7mREVF3bt3D/uWRCItWbJk1KhRdnZ2wcHBUVFRR44coVAopqamZmZmza9KQkJiy5YtJ06cuHfv3s2bN7W1tV1dXb+d36TT6YITxE2bNq2ioiIiIoJKpbq4uEyaNGn//v0vXrywsLDQ0tJauHDhqVOnIiIievfu7erq2oYwQHQoKSlhE+igbWRlZQMDA4ODg6Ojo3///Xc1NbW4uLhnz54pKyvb2dkJztDh4ODw4cOHlJSUzMxMJyenwYMHN7VCwfCimbVhn/6ytLT8dreelpbWrl27jh07dunSJezAUnd391/50cT18+lcLpdEImFf19bWbtiwgUwmi+nBd/D5dJFVXl6+e/du0bn8rEjp/PMWd76mPp8urm/X/fv3f/r0adCgQQoKCgUFBXl5ec7Ozh3xRGw2G9tCB92QqqqqhIREfHw8HM4pCr7d8sOXuI43Hzx4cPPmzQ8fPnA4HE1NzZEjR06cOLHdC66+vp5IJLbhMIVWgfGmKOPz+UwmEz7i9aPufP5NcX27Dhs2bNiwYZ3wRB1dmkDEEQgE7MRXUJ34IhAIQisMF7Abtzmi83sCOMrJyVmxYgXeKYAI/emC3mwSg8FoyTFloMvDdtdin8oFOBKdk5eLx/xm518/vby8/NixY6tWreqE55KUlOzoM4cC0O54PF5nfo6DwWCEhIRs3ry5056xmeuni8f8JplM7uQ9JzU1NRMnThSd8x9NuKsAACAASURBVEsDfNHp9NTUVNir/i0ikdiZbxAikWhlZSUib0nxGG8CgLsZM2YEBQXBJxcAzG8Kx2QyFy5ciHcKIFqCgoJE5/rd3RCTyTx06BDeKRpBbwqRlZUFE47gO2ZmZoMGDcI7RffFZrMvXryId4pG0JtCGBsbi8XpTkAni4iI6IRLgwGhpKSkBJdOwB30phCqqqpwdmHwo6qqquTkZLxTdFMSEhLYRW5EAfSmEBs3biwvL8c7BRA5s2fP7tevH94puimY3xR1N27c6OSPwQKxoKqqCvvT8QLzmyKNxWKdPXsW9gsBoYKDg7HLsYBOBvObIk1SUtLY2BjvFEBESUhIZGZm4p2iO4L5TZGWlZUVFBSEdwogohYtWiS4bDfoTDC/KdJqampgIx00RU5OTl1dHe8U3RHMb4q0/v37Y1fHBOBHPB6vqWt4gQ4F85siTU1NzdDQEO8UQEQRiUQCgZCXl4d3kG4H5jdF2r179yIjI/FOAUTXsWPHNDU18U7R7cD8pkirqqqCg95BMxQUFETnxOPdh0jNb8J55L7H4XB4PJ7Qi80DgBBKSUnJzs5evnw53kG6FzabHRMTIyKb6uJx3uJOMHfu3KysLOya7NjfEgKBoKure+3aNbyjAdGirKz89u1bvFN0OzC/KYp8fX0F5/IgEAjYoUiOjo545wIiZ8CAAVu3bsU7RbcD85uiyN7evlevXt/eoqenJzp/34DoIJFIGhoaeKfodkRqfhN68z++vr4KCgrY1wQCwd7eXk1NDe9QQBT5+/vDzsNOBsdviih7e3sDAwPsaz09PW9vb7wTARHF5/NLSkrwTtG9wPym6PLz88OGnMOHD4fBJmjKoUOH+vTpg3eK7gXmN0UXNuTU0dGZOnUq3lmA6KJQKBISEnin6F5Ean7zJ8dvlv7LfHanqjivoaGW24mp8MTn8/l8PpHYXf6iqGhLSUkTTWzkjX+j4p1FbERERFAoFD8/P7yDdCNic/zml7f0h/E08xEq5iNUZKikTkwFOg+XxS8rZPz7vp5WxLQbC2e5bxEZGRkajYZ3iu5FpOY3mxxvvs2sffek1tFPu9MjAXxk3S7ncXmjvOEkaT8HHyrrfEwm8/jx4yKyS1341iiTznufBaXZvViPVuXzCf++b8A7iBggk8lQmp1MpOY3hfdm4acGAhHO3dvtyMqRCz7Q8U4hBp48eQKfT+9kYnD8Zk0FR1NfptPDAJyp6kg10Hl4pxADkpKSlZWVeKfoXkRqfrOp7XQuiwHvn26Hx0O1FWy8U4iB/v37h4eH452ie4HjNwEQb0QiEU7B2cnEYH4TANCM8vJy+BhuJxOD+U0AQDPIZDKc16OTicH8JgCgGQoKCpcuXcI7RfcC85sAiDcCgSA4yzXoHDC/CYDYg2sBdDKRmt+E6wsBfNTX17NYLLxTtN38+fMrKiqw66mIKUVFRTHKL1Lzm9CbAB8cDofNFuNjRYcOHcrhcPBO8Uv4fL4Y9aYYfD4dANA8MWqcrgHmNwEQexUVFc2fuxa0L5Ga34TeBKAtoDQ7mUjNb0JvAhHy7t07JpPZOc9VXV29Y8cOT0/PGTNmtOEkHcrKyrCp3plE6vjN9twvxGKxzl84lZScUFJSJCcn37uX0dy5C/sYmbR5hW/evurdy0hKSupXUnG53DdvXvbvb9HC5UtKis9fOJmRkV5OK6NQqAMH2s6dvUBdHf/rZbfLqyHKkpKS9uzZc/78+c75GQ8fPvzy5cvAwEAKhaKkpNTah0NpdjJsflNENtXbbbzJZrNXr1l08lSEtpbOVG9/+xGOZeWl0lJtP/fBrcS4wAUzGIxfPY3uzr//2h0W0sKFX7/+Z85c74SbsSYmpt5e0y0trO/eTcp6+vgXM/y69no1RNlPD0tq303jrKwsd3d3e3v7gQMHtvxRggyVlZWiuakumql+nUjNb7bbePPsuRPPs7MC/1jmMdmnXVbYXttrrBavp66ubuOmlRKSkvv2HjMw6I3dWFCQr6nZGee9b/6gkDa/GuJyrElSUtLBgwcRQtiVRJcuXerk5PTgwYNt27b9+eefV65cycnJ8fDwcHFxOX36dFZWVn19vY6OjpeXl729PbYGT0/PwMDAR48eZWZmUigUV1dXHx8fhBCDwQgPD8/IyEAImZqaBgQElJeXr1ixAiF06tSpU6dOHTx40MDAACGUkpJy6dKloqIiZWVlZ2fnKVOmEInE6urqqVOnzp49Ozc39/Hjx7179965c6enp6efn9/Tp09fvHhBoVBGjhxpZmZ25syZwsJCPT29BQsWGBkZNf/zFhUVHT9+PDs7m0wmjxo16sOHD8OHD3dzczt16lRMTExsbCy2WE5OzpIlSzZv3mxtbY0QevHixcmTJz9//qyoqGhubu7v7499bGn+/Pl6enp6enrXr19nMBiTJ0+Ojo4+c+aMvLw8tp6dO3e+ffv2+PHjHfxr7EAiNb/ZPr3JZrNjrl7o2VN/8iThl8998/bV4Yiw9+/fSEvL2NkOnz9/qbycPEJo/YblPXT1yGRy/I2rHDZ78OChixetplKptxLjwvZuRwhNmOSIEFq1cqPzGHeE0PPsrKORB3Jzc5SUlC0tBs6ZHaiioooQch9vv2TxmrS0O48z0igUqvvYyf7T5yKEtocG37mbhBAaOcoaIXTu7HWtpkswMTGORiv/c32IoDQRQrq6Pb9dprUBsPdt5LGDKam3WCxmD129KVOmOYwcjRC6ey950+bVf23adTH6zLt3r6d6+/v5zj595mhqamJpWYmKiupoJ7cZ/gEkEqmpV6OpV3Xm7CkG+r319XvHXL3AYjET4h+0y2+5Q1lbW0+aNCkmJiY4OJhCoWhr//drCg8P9/f3nzZtmo6ODpvNzsnJcXV1lZeXf/jwYWhoqJaWlrGxMbbk7t27fX19PTw8Hjx4EBUVZWhoaGNjc+nSpeTk5GnTpikpKaWkpEhLS/fo0WPdunVbt251cHAYMmSIhoYGQig5OXn37t329vbTp09/9+7d6dOnEUKCkx5duHDBzc0tJCSERGq8QOGJEyfmzp3r6+t75cqVq1ev3rt3b+HChdLS0uHh4SEhIUePHiWTm3xzVVZWrlixgslkTp48WU1NLS0t7eXLl8OHD2/+JcrOzt6wYYODg8O4ceNqampiY2PXrFmzd+9e7Ix2T58+ZTAYGzdubGho0NPTu3Dhwv3798eOHYu9PTMzM7GvxZdIHb/ZPr354cO72toarynThA5t8vI+LQ+ap6/fe+WKjdVVlSdOHi4tLf57V+MU76XoKIeRo0O2huV/+bxr9xYVFbV5AYsH2QyZ4ul3KTpq29YwCoWKldfTZ5mr1yxycnSdOMGrtqb6Ssz5ZUHzIg5FYf9vtu/YOMM/wNvb/+7dpJOnIoz79B08eKifz6yy0pKioq9rVm9GCKkoqzbzU2RmPZKRkRk+zKGpBdoQgMfjrVu/tLi40NdnpqKicnZ21l9b1jIYDa4u47F17t2/Y86swFkz5+vq9CSRSE+fZtjaDdfW0v348X3U2eNycvJTPP2EvhrNv6pPnjxiMBkhW/bQG8TjuhdKSkpaWloIIWNjYwUFhW/vcnd3//ZDjYcPH8b+m40ePdrHx+fRo0eC3hw9ejQ2JOnVq1diYuKzZ89sbGxKSkqkpaU9PT3JZLKzszO25KBBgxBCPXv2tLW1xUblp06dMjU1XblyJUJoyJAhdXV10dHR48c3/ppMTExmzJjxbSonJyc3NzeE0KxZs9LS0ry8vLB1Tpky5e+//y4qKurRo0dTP+zly5crKip2795tYmKC/c3ARtnNO3z4sIuLi6A4rKysAgICnj17Zmdnh52iadWqVTIyjZdp+O2331JSUrCufPbsWX19vWBgLqZEan6zfXqzuKQIIaSlpSP03qizx4hEYuiOA3JUOYSQnJx8yPYNL148Mze3wgZ0a9f8RSAQ+pqY3k9LfZL1aF7AYiUlZW1tXYRQ375mCgqK2Hr2H9jpPnbSooUrsW+trQf7z/R4kvVo2NCRCCFXl/G+PjMRQoa9+9xIuJaZ9Wjw4KG6uj0VFBQrKmkt2S9UXFyIDX4Ft5SWlmBfKCurkMnkNgS4/yD1n5fPz5+NU1VVQwg5jnJuaKBfiTkv6M2JE7zGjPlvIBB+8JTgb09hUcH9B6lTPP2EvhrNv6okMvn/2rvvsKau/w/gJzshCXvKUhFBUVBEBNQqCiJUUdRqnYgLrdW22roqLY66WlHrwipOWvcAAUFBUcDFcCsiRUU2hJAQyE5+f1x/KV8EZJ/ccF5Pnz5wk9y8c4UP595z7jkhP29R/Rbh2oAB//Nvl5eXFxkZ+ebNG6zTr6qqSvWQai5hEolkYGCALdXr6emZnJwcEhISHBzcvXv3Bt+isLCQw+FMnjxZtcXZ2TkhIaGwsNDIyOjTDFipxa6BYAu0USgUbLuhoSEAgM/nN/GJHj9+3KtXL6xoNlNpaWl+fn5RUVF8fHzd7eXl5dgXdnZ2df+5vby8tm7d+uHDB0tLy9TU1B49elhbWzf/7dSQBl7fxC5FN7bC3+MnmQMHDsZ+vQEAgwe7AwBe57zEfsPpNLqqUpiYmD1//qTBnZSUFL9//7aw8ENM7OW621WljU7/+ENDIpGMjIw5FeWt+BRE4v90lE2b/iX2xYljF6hUWisC3L+fKpPJZszyVz1fLpczmSzVt87OrnX3xuVWnjx1OD3jfnU1HwCgOmifavqo9unTTzOKJrZYuepr7FzV0dHxhx9+0NLS2rx5s0LR8IIuZDJZLpdjrbkNGzZERER88803Pj4+S5cu/fQMuqamBrtfW7WFzWZj8xNjdfPT2d3bctVYIBDY2Ng044n/wUZKzZgxY+jQoXW3q6ZlqpfQzc1NW1s7KSlp5syZ9+/fnzp1aqvTqgkNvL6pr28AACgqKmjw0Zoaga7Of+M82GxtAEBFQ3WNQqYoFPIGd8LlcgAAgXMW1TuP1m/o1JtMIssb2U8TDA2M/s17U7cjZcvmXQ8epkVFX2h1AC6XY2BgGPZHeN1HSXV+b7UYWqqvKys5ixbPZDC05gUt6dbN4ujRAx8K3jeWtumjyqDjtWg23R185swZMzOz0NBQrPY1c7EKFxcXZ2fnqKiow4cPm5iYfDpVO1YceTyeagvWjMWqZ4OoVGqrS6e+vn5lZWWDDzW2TxaLhV3ja+L0vy4KheLp6ZmUlGRvb19TUzNixIjWRVUfanV9s33GIfW27UOlUpOS4ht81NDQmM//7yeSy60EALAab0nVpfotwp4vFousrLrX/Q/7eWrmTprm6OjM5/Mept9TbXF3H96jR6+2BGCztauquCYmZnVfYt7NosEnR1+9yOVW/rHjwOhRPn3sHYyNTZv4IG05quoJK4KNFRQMj8fr2bMnVjQlEolQKGysvamCDW8iEokBAQEGBga5ubmfPkdfX9/ExCQjI0O1JSUlhUaj9ezZs7HdtqW9aWtrm5OT02ASHR0dqVSqOs0vLf14NmNubm5sbHzjxg2h8ONYtM9OjOLl5cXhcA4fPuzg4GBsbNzqtGpCA+9PZzKZo0eNzXmTffnKf5NgFxYV5LzJBgA4ODg+fpIpEomw7XfuJAEAPnvBEWsxqRpQFhZWJiam1+Kjm/9zg6HTGZWVnM/+dmEXKOl0+q7dW4qKC1UbZf//Fq0L4OzsKpfLo69eUG1RvfxTfH6Vrq6eicnHcsnjV6kKZb2j0eqjqs769u1LIpEOHTqUmJgYFxfX4HOcnJwePnyYkJBw79699evXCwSC9+/fN/13MTo6+scff4yLizt16hSHw2lshNDMmTMzMzP37NmTkpKyd+/ee/fuTZkypYlrHWKxuNUjJSdPnkylUn/++eczZ87cuHGj7m0wAwcOJBAIhw4devPmTWJiouohAoGwaNGiysrKFStWxMTEREVFrVixIjY2tol3sbGxsbS0LC4uxnuPEIZKpS5atAh2io/abfxm8KLlT589+nPvjvv3U+ztHSoqypNv3+jbp//vO/bPmjHv5s2E1WuXjR83uays5MTJvwYOcBngNKjpHTr0cyKRSPsO/OHr4y+WiP3HT176zcpffv1p6bK5/uOnKOTyhOsx3t5+nx0u6uTofC0+OmzXlv79BrDZ2h4ejY72MDY2Wbli/ZatIfMXTBs+fJSpiVlRUcHtO0kkEolCpRIIhFYE8PbyuxpzKfzQnuKSot629rm5Oalpt44fvdDgCeaAAS6Xr5w7euygg4NTSsrNBw/SFAoFj1elo6P76dFo3VFVZ2ZmZsuWLTtx4sShQ4dsbGz8/Pw+fc7s2bMrKysPHTrEYrF8fX0nTZq0d+/eJ0+efNpvU3e3Uqn0yJEjWlpa/v7+dTt/6vLy8hKLxZcvX05KSjIwMAgKCpoyZUoTadsyvNzExGTz5s0RERGnT59msVh1B95bWVmtWLHin3/+WbVqlYODw7x588LCwrCHPDw8QkNDIyMj//rrLyaT6eDg0K9fv6bfyN7evri4eNiwYa2Oqj6oVCo2IFcdEBr8538YXykWgQGeLVsJgMerOn7iUGpaclUVV1/fYOjQkXNmLdDV1QMAPH6c+deRvbm5rxkMreHDPBcHf4+d3q7/ZWV5Wemh8EhsDwfDd8ddu3I1Khn79lp89JGI/RKx2NbWPmxnONbNcux4eN7bXCaT5dh/4KxZ87H7OMdPGOnnO3HJ4u+xFwYvnmVkbLJ5404AgEKh2Lf/j+s3Ymk0+lif8QsXfNv0p3j27PHfp4+9fPFUKBKaGJsOGOASMHGajc3HRkorAggEgsNH9t6+k1RbW2NhYeU12nfqV7PIZDI2fvPEsQtWVv918h47Hn75yjmgVLp7fDF50vSt234Z8cXouYHBDR6Nxo4qNn7zl5CtLfrnAwAU5ta+Tq+asLgzxvnzeLxOuxW9I8jlctVYzjbChtYvXboUG9jUjjZt2iSXy0NDQxt81NDQsF5HqDoTiUSnTp1auHAh7CCgnesmgneobrajn3766d27d59ud3NzW7lyZd0tHVE3b926devWrczMzC1btjg5OTX4HHzVzaqqqsmTJyclJcEOArrcfO8CgWD6zIbvmghe9N24LwM6PRGCV3w+n81mN9E7tGbNmgYvfzdzDEAbXb9+XSqVbtq0qbGiiTt0Oj0oKAh2io+6VntToVCUlpU0+JA2W4fJZHZ6IvWC2pvNV1lZqaenh4t7/xuDr/amWula7U0ikdjE/ekI0nza2tq4Lpq4U1tbe+7cuXp3u8KC/togSGs0MW0H0hGqq6vPnTvXjCd2BlQ3EaQ1qqurNXWmS/XEZDLnzZsHO8VH6G8mAodqakicWrhwYUREhIGBAewgrYev6wwsFqvpEbWdCdVNBA58/dJ+at26degSZ2ficDgJCQlqMvQdnacjSGsMGTKksQnAkI5QXl7e2N23nQ/VTQRpjU2bNtWd+hPpaIaGhrNmzYKd4iNUNxGkNR48eKCaVAXpBIaGhqrp+qFDdRNBWmP9+vV15zlGOlp+fn5MTAzsFB+huokgreHm5tY5d0wimJycnJQUdVlhsOG6SaESqXRUUrscIonA1EZDLJplx44dZWVlsFN0IVZWVr6+vrBTfNRwcWTqkDjFOL53GGmdqjIJhYYG1jRLenq6QCCAnaIL6d27t/pMwNxw3TToRlMq0L0QXY64Vm5qhc49m2X16tXYwutI53j06FF6ejrsFB81UjfNqNoG5Me3mlrpBdEwJe+ExW9r7QbjeIWizuTi4oIm0OpMt2/fzs7Ohp3io0YvYg6faAgUiowEjlT8+ZV5EFxTyMHb54KsRM7kZeaws+DGH3/88f59o6uNIu3O2dm57oIicDXVCTB8kmFmEjc6PB8ogRZLE7oLFEoFUILOmXNQCZQKuaK9llLoODQtYkFurYO7zrSVDa+yiTTo1atXXC7X2toadpCu4osvGl0ZrPM1PG9xXUolqObKavmyzorUgb7//vvQ0NBOG3bH5XI3bty4a9euznm71qHSSfqmFNgp8CcnJ8fMzKyJBdaR9hUdHe3q6mpqWn9xbCg+Xzc1RnZ2dklJSSd3ycnl8tLS0m7d0GTJCNImEydO3Ldvn4WFWpwVdaFBmvb29p0/joFEIuno6ERFRXXy+yIdbdeuXY8ePYKdoguZMmWKmjQ2u1DdzMjIOHPmDJS3ZjKZQ4YMmTRpEpR3RzpISUkJh8OBnaILmTVrlvrMsd9VztP9/f0PHjxobo76i5H2weFwGAyGlpYW7CBdQkVFRWxsbGBgIOwgH3WJ9qZIJIqMjIReNHk83uHDh+FmQNqLgYEBKpqd5tWrV2p1VaRL1M2cnBx1mGJWR0fnq6++2rFjB+wgSDsIDw9Xn2l0NZ6ZmdmcOXNgp/iP5tfN69evnz59Wk2mrtHV1V21ahUaL60BhEJhZSW6oa6T9OrVy9nZGXaK/2j+9c24uDgPDw+1mipRJpNNnDhRfSYTRFqhsrKSSCSq1c+VBrtw4cKgQYN69OgBO8hHml831VNJSUlJScmAAQNgB0EQHBg3btyRI0fQOKROEh4enp+fDztFA0xNTfv27VtYWAg7CNJKN27cOHnyJOwUXYJMJps3b576FE0Nr5uPHz9OT0+3srKCHaRhVCrVzMzM1dVVLpfDzoK0mEgkysvLg52iSyCTyeo2/FmTz9Nzc3MNDQ3V/AqUXC6/e/euq6srjUaDnQVpAR6Px+Px1PavsibJyMioqKhQn0XZNLm9qVQqLSws1LxoYjdiDh8+/N69e+oztyDSHDo6Oqhodo6rV6/KZOo1r5DG1s0dO3ZER0fDTtFcI0eO3LRpk1QqhR0Eaa43b9789ttvsFN0Cd7e3p6enrBT/A/NrJtKpTI3N3fq1Kmwg7TA33//LRKJ3r17BzsI0ixEIvHJkyewU3QJw4YNU7ep9TX5+iYePXny5M6dO8uWLYMdBPkMmUyWn5/fs2dP2EE03JMnT9LT0xcsWAA7yP/QzPbmw4cPhUIh7BSt4eTkxGazP3z4ADsI8hlkMhkVzU5w7do1HR0d2Cnq08D25qNHj/bv33/kyBHYQVqPx+PJ5XJ9fX3YQZCmTJo06ezZsxQKmi2/A/37778WFhbqNtpEA9ubr1+/Xrx4MewUbaKjo6Otre3m5iYSiWBnQRolFAq5XC7sFBrOxsZG3YqmZrY3NYZUKn3y5EmvXr3UfzRV11RZWamtra0+k+lqnvPnz/N4PHW7uKmB7c3nz58nJCTATtE+KBSKi4tLVVXVnj17YGdBGqCvr4+KZoe6evWqu7s77BQN0LS6uW/fPg27LNi9e3c9Pb1nz57BDoLUt3///rS0NNgpNNnJkycdHBxgp2iARtVNqVQaHBysPovTt5c5c+ZYWloWFxc/f/4cdhbkP1Kp9O3bt7BTaKyamhqBQAA7RcPQ9c12plQqO+6QLl++PDg4WA3/AhOJGvUHuJkqKipkMplazdOjSSZMmLB//341Wfi3Ho2qmyEhIbNnz+7duzfEDAqFoqKiouP2L5VK1W3gC41GU8MRdgiuZWdnX7t27YcffoAdpGGa00yoqKh4+PAh3KLZCbCiyePx1G2mgy4oOzt727ZtsFNoJnt7e7UtmhpVNxkMxrlz52Cn6CQ6Ojq1tbWwU3R12traqF+oI9TW1qr5KjKaUzeZTGaXOlvU1tbGhl4rFArYWbqobt267dy5E3YKDRQWFqbmc4NpSN2Uy+XTpk2DnQICGo3G4/Fgp+i6NP66UOcTi8Wurq4BAQGwgzRFQ+rm3bt3zczMYKdoZ9nZ2WKxuOnnEIlEPT09rL+o1Q3PvLy8n376KSAgYN26dU08jcfj+fn5xcbGtu5dNNLatWvRbHLti0ajjRkzBnaKz9CQujl8+PDdu3fDTtGebty4sWLFiubfn04mk6uqqlpROqVS6caNG5VK5bp162bPnt3ypF0ai8X6999/YafQHAUFBd9++y3sFJ+nIXeJlZWVadhNbxKJpEXPJxAI+vr62BJvcrmcRCI184X5+fllZWWrV6/u06dPq5J2aT///DPsCBrl3LlzCxcuhJ3i8zSh0JSVlQUGBl67dg12kIZduXLl9u3bAQEBJ06c4HK5NjY2y5cvt7S0xB5NSko6d+5ccXGxvr7+2LFjp06dSiQSb9y4sX//fgDA9OnTAQA//PCDt7d33X3KZDJ/f/+5c+eq5rQPDQ3l8Xi7du0SiUS7d+/OysoiEAgODg7BwcEmJibY/K/Hjx9/+/atrq6uk5NTYGCgvr7+6dOnT506BQBYuXKltrb2mTNnmthzJx83pAtasWIF7AjNognn6Xl5eePHj4edoimvX7++dOnS8uXL169fX1FRERYWhm1PTEzcuXOnjY3N6tWrhw8ffvLkSWwolYuLC7bwaWho6O+//+7i4tL89zp37tydO3fGjx8fFBRUXV1Np9OxJZFDQkKsra2/++67gICAZ8+erV27ViQSDR8+fNasWQCAoKCglStXdtTn11zl5eXYAUTa7uLFi3hZE1sT2ptubm5ubm6wU3zGr7/+inXg+Pv7Hz58mM/ns9nsEydOODg4rFq1CgAwdOhQgUBw/vz5CRMm6OnpYd1cdnZ2LR1cVVpaSqfTp0+fTiaTPT09sZ6l8PBwX1/fJUuWYM9xdnYODg7Oysry8PDATs/79+9vb2/fMR9dkxkZGRUUFAgEAhaLBTsLvq1fv37o0KHNv74ElybUzezs7O7du2MNK7WlimdsbAwA4HA4fD6fw+FMnjxZ9RxnZ+eEhITCwsJevXq1+o08PT2Tk5NDQkKCg4O7d+9OIBAKCgry8/OLiori4+PrPrO8vLwNHwj56MKFC1QqFXYKfKuqqlqwYEH37t1hB2ku3NdNoVC4YMGC1NRU2EGaC+u8UigUNTU1AIC6cxKz2WzshtG21E0XF5cNGzZERER88803Pj4+S5cuxSaVCQgIGDlyZN2uD6xgywAAIABJREFUMw2bcA8WQ0ND2BHwTalUCgQCHBVNTaib79+/HzduHOwUrWFkZIQNilRtqaqqUlVPTGOzrhAIhCb27OLi4uzsHBUVdfjwYRMTk2HDhmEjPU1NTRkMhkKhaGL6oqb3jHwqOTk5PT39p59+gh0Er2bMmLFhwwbYKVoG9/1C9vb2a9asgZ2iNfT19U1MTDIyMlRbUlJSaDQatkoidl5fWVnZ4GtJJBKbzVY9qlQqy8rKsK+xAUxEIjEgIMDAwCA3N9fc3NzY2PjGjRvYE8RiMZfLbew+tib2jE0pUl1d3X7HQBPY2Nigu9RbLT09fdOmTbi77Qr37c3y8nItLS11W5a+mWbOnBkWFrZnzx5nZ+fHjx/fu3dv5syZDAYDANC3b18SiXTo0CFvb2+JROLn51fvtc7OzklJSU5OTnp6epcuXSooKLCxsQEAREdH379/f9SoURwOh8Ph2NraEgiERYsWbd68ecWKFV9++aVcLk9MTPT09AwICGiwddnYnrW0tMzMzC5fvqyjo+Pr69tZB0ndWVpadp0JZdqXUqkcNGgQHidvxV/ier755pvS0lLYKVrJy8tr6dKlz549+/3337OysoKCgmbMmIE9ZGZmtmzZsoKCgkOHDt25c+fT1y5atMjR0XHnzp1bt261sbEZOHCg6oVSqfTIkSMJCQn+/v5Yv5OHh0doaCiFQvnrr7/OnDljYmLi6OhIIBA4HM6nA+wb2zMAYNWqVd26dUtMTOzIo4I/tbW1n70jFqknPT19yZIleCyamjBv8dKlS7Eh4mqio+ctbndisZhGo8lkslbfbYXmLT5x4gSPx1u+fDnsILghEAiio6NVrQTcwWWxr0utiiYeYYtTK5VKDoeDpqRrHQ8PD9VVYKQ5GAwGfosm7tubJSUlpaWlTk5OsIP8B3ftTRWlUqlQKEgkEtYCbf4LUXsTaREPD49bt2616GdM3eC7vRkXF4ejkZtqjkAgYHdryOXyxvrxkcZUVlY2f/KqruzChQvJycm4Lpq4r5v6+vpDhw6FnULTaGlpYbeEymQyVAua6fr163v37oWdQt29efNmypQpGnB7Fb7r5sSJEwcMGAA7hQbCxieRyWSZTIbd14Q0beTIkQUFBbBTqLVhw4b16NEDdor2ge/rm/Hx8SNHjlSrO9OVSqWGjQzHutofPXrEYDAanPuDQqFgY04RpEEymezRo0f9+/dXq1/VtsBx3VQoFEOGDElPT4cdpEuQyWSHDh0aNWpUnz59ampqcHqjQYd6+/YthUKxsLCAHUS9ZGdn19bWOjs7ww7SnnB8ns7n82fOnAk7RVdBJpOXLl2KTTo3fvz4I0eOwE6kdng8XmhoKOwU6oXH423evFnDiia+25sIRDdu3PD29n78+DGdTkcTd6qcOHFi2rRpGnM22kYlJSVCoVBjrmnWheP2ZllZ2cuXL2Gn6KKwdTtMTEw2b9588+ZN2HHURWBgICqamA0bNkgkEo0smvium0lJSXFxcbBTdGlmZmaRkZF9+/YFAISEhERHR8NOBFlBQcGVK1dgp4AvOzt74MCBVlZWsIN0FBzXTR0dHc27boJHpqamAIAlS5Y8evSosLCwFYtxagwLC4vw8HCc3jDWLrKzswsKCiwtLf39/WFn6UDo+ibSnrBJkb28vMaNG/f999/DjgNBVlYWnU7H2uBdzatXr3777bfIyEjYQTocjtubGRkZaIUcdYNNC5aYmIgte1BYWNjVBoo5Ozt3zaKJLfHSFYomvuvmvn37SkpKYKdAGjZx4kTsWkpERMSff/4JO06n2rlzZ5e6d6ioqCgoKAgAMHz4cNhZOgmO66abmxsaY6zmWCxWeHj41KlTsbWI9+3b19j6HJrEysqqizS7MAcPHty1axfsFJ0KXd9EOolMJjt16tSgQYMcHR0fPXpUdxp5zSOXy/GyFHirSaXSf/75JzAwEHYQCHDc3rx48SLsCEgLkMnkoKAgR0dHbLbp7du3w07UgTS+aAIAvvzyyy+++AJ2Cjjw2t6sra318fFJSUmBHQRppYKCAgsLi2vXruXm5gYFBbFYLNiJ2lN2dvbvv/8eEREBO0iHSExM9PLygp0CJry2NxUKxbRp02CnQFoPuzY9ZswYNpsdFRWFTc4IO1S7sbe3Z7FY2dnZsIO0Mz6f7+bmZm1tDTsIZHhtbyKa59ChQ/Hx8adPn0a3KqqnqqoqHo9nbm7e6iX8NAZe25tcLvf27duwUyDtKTg4eM+ePXK5HBvKk5eXBztRW0VGRmrG+sC5ubmurq40Gs3a2hoVTRzXzdzc3NOnT8NOgbQzKysrbGZPOzu733//HQBQXFwMO1TrCYXCY8eOAQAmTJjg5uYGO05rYAul5OXl3bt3D81OrYLXuslisdDKQhps3LhxBw8eBABwOJwRI0ZkZmbCTtQaQUFBZ8+eHTRoUGFhoUKhiImJgZ2oZWJiYtatW4ddhu4KIwSaD691s0+fPrNnz4adAulw/fr1i42NxZY/jIiISEtLa/Bp2NB6teLp6enm5lZdXY0t1kSn03G0HhmfzwcAfPjwISwsDHYWdYTXullUVPTq1SvYKZDOwGKx+vXrh627ffbsWewWRqFQqHrCuHHj3r17t3LlSqgx/4evr2+9ZabIZLKWlha8RC2wb9++5ORkbI4r2FnUFF7rZkpKytWrV2GnQDpVnz59/vzzT2zaOm9v7z179mDbS0tLFQrF/fv3t23bBjvjR8ePH683+ySFQlH/uimTyV68eMFkMjV7Fri2w2vdtLKyGjRoEOwUCARYf25qaqqTkxMAYOzYsdhYOrFYnJCQcOLECdgBATYT/qVLl1xcXLAJonDR3tywYYNIJOrduzc2SQfSBLzWTXd399GjR8NOgcA0cuRIAEDd0+Hq6uq///772rVrUHP9Jzw8fNy4capuaHWum5s3bx44cCCLxaJQKLCz4ABe6+bTp0+fP38OOwUCX90LnQCAysrK/fv3v3jxAl6i//HLL78sXLhQR0eHSCSqYb8Qh8M5dOgQAODnn39G5+bNh9f7hXbv3m1gYIC61HFHIQeZiZVlH8S11fK27+39u3dyhRwAAvYt4f8RiURLS8u277+91NTUVFVxzc3VbtrD9+/fm5qaYsMV1I2uEYWmRerZj2nRW+3GjeK1bt6+fVtPTw+bXAfBC06x5Mwf+QM9DXSMqAwWGg+INElJKC8UckvE+qYUVx992Gn+B17rJoI7ZR/Edy5V+Mw1hx0EwZn7seW6huTBY/RgB/kPXq9vpqamvn79GnYKpLmUCpB8vszzazPYQRD8cfvSqKJIkv9a2IzndhK81s3ExMScnBzYKZDmKswVkihEKh2vP28IXCbWjNxH1c14YifB68/xiBEj7O3tYadAmquyVGLaQ31H4SBqzsicLqxph47E9oLXKaE8PT1hR0BaQFQjV8hgh0Bwi0AicMsksFP8B6/tzcTERA2YnxFBEDzCa92Mj4/Pz8+HnQJBkK4Ir3XTy8urR48esFMgCNIV4fX65tixY2FHQBCki8Jre/PatWsfPnyAnQJBkK4Ir3UzNja2sLAQdgoEQbqizjtPF4lEUqm0vfa2cOFCIyOjelNqtwWLxcLWM0AQBGla59VNiUSCrY3XLszMzD6dQ6wtmEwmqpsIgjQHXs/TJRKJQqGAnQJBkK4Ir3VTKBTK5Wp03xWCIF0HXusmjUZTrdyCIAjSmfBaeuh0Oon038S3eXl5P/30U0BAwLp165p4FY/H8/Pzi42N7ZSMCIJoJryOe5dIJGQyGWtySqXSjRs3Ghoarlu3jsViwY6GtINZcwIKCxsen3vi2AUrq+4d8aYKheLY8fBr8dESiWTdmo1ubsM64l0axONVTZzkFTR38ZzZC1Qbf/9j081bCddiUzv63SsrOUci9t+7n1JTIzA17eY50nv613PpdHpHvy9+4bVuCoVCLS0trG7m5+eXlZWtXr26T58+sHMh7eOrKTN5vCoAQEVF2dWYSyNHePXo0Qt7SEdHt4PeNCb28ukzJ4IXLbe0sO7Xb0AHvYu64fGqln83v5LL8fby09PTf5X94uSpIxmZD3aH/YXWtmwMtLopk8n8/f3nzp07depUbEtoaCiPx9u1a5dIJDpw4MCDBw8AAA4ODsHBwSYmJgCAJ0+eHD9+/O3bt7q6ug4ODnPnzjUyMjp9+vSpU6cAACtXrtTW1j5z5kwTe4b1YZGWmuA/Bfvi5ctnV2MuDRvmOXqUz6dPUyqV7Th67GH6XeeBg7+aMrNFr2rfDB2h6YSHj+wrKS3ev++4Xe+PzY4rUef3/Ln9wsV/pn8d2AkB8Egdr2+eO3cuMTFx4sSJQUFB1dXV2PnC48ePQ0JCrK2tv/vuu4CAgFevXq1fv14kEg0fPnzWrFkAgKCgoJUrV8LOjnSs5NuJnqNdUlOTl30339vH7djxcIlEciRi/4yZ/l5jhkyb/mXE0QOqgRbrf1l56K8/I44eCJjsPd5/5G9b1gsEAuyhf04fn/q1n++Xw5Z9Nz8z6yEAYLS3a1ra7fSM+56jXS5dPos97fr12MCgKd4+bl/PGHcqMkI19C1o/tSNm9aePHVk4iQvv3HDBQLB+Akjr1+PXb12+Zix7pOmjDlwcFdqWvL8hV/7+HosXjL7dc6rNn7w+/dT5y2YNtZv6Nx5X6niFZcUhfzyo9+44RMnea1a/W3265fY9j1/bp80Zczdu3dmzQnwHO2S9Si9sd3W1tbeSIxzdxuuKpoAgIkTvrKwsIpPuAoAyMh84Dna5eXLZ6pHfb8c9tfhvS0KcPnKOc/RLvfv/3fBITbuiudolzYeE4jU8Ty9tLSUTqd/9dVXZDJZNX9HeHi4r6/vkiVLsG8dHR2XLl2alZXl4eGBnZ73798fzQDfRezZu33BvKXzgpZYmFuRSKTMzAfuHl90M7PIzX0d+fdRNlt76lezsGeeOx85ynPMlt92579/+0fYZgMDo8XB32VmPTx8ZN/o0WOHDPZ4mH5XWFsLANgY+vtfR/bSqLQ5cxb27GkLAEhIiNm2I3T06LHz533z8uWzo8cOAgBmz5qP7Tk9/Z5ILNqyeVetsBa7qr5z12/fLFkxNzD47NmT5y/8ffNWwsoffqYzGLv3bNuwYfXJE5fI5Fb+utXW1oZuXN3duufKFevfvs3lcMoBABxOxbLl88zNLb9d+iOBQLh+Pfa77xeEHzjVo4cNAKCmRhBx7MD3360RiYTOAwc3tufXOS8lEomLi1u97U6OzrFxV2pqappI1fwAQz1GREWfT7geo7pkfOdOUr9+Tq07GupAHeump6dncnJySEhIcHBw9+7dsUqan59fVFQUHx+PPQdbhrO8vBx2WASCgInTfHzGqb49sP+E6jSwqLjgTspNVd20sLBat3YTgUDoY+9wJ/Vmesa9xcHflZQUAQACJkx1cHD09vbDnjl06Igz504y6IxhQ0diP2BHju7v33/A+nWbAQBfDB9VXc0/c/bE5EnTtbS0AAAkMjnk5y0Mxn9Le/uO9ccuLwQHf3f7TtLMGfPc3YcDAGZOD9q6/deiooJWd2dxqyrFYvHw4aO8vXxVG09FHtHT1d/5+0GsHHt7+c2aMzEm7vKypT9iHac/rljfp0+/pvfM4VQAAAwNjOptNzAwBADw+FVNvLZFAXzH+h89dpBfzddma/Or+VmP0pd+g+OzQ3Wsmy4uLhs2bIiIiPjmm298fHyWLl3K5XIBADNmzBg6dCj2HLFYTKFQDA0NYYdFIHB2dq37LZdbefLU4fSM+9XVfAAAm8VWPUSn0VUl1cTE7PnzJwAAtyHD2GztLVtDln37U2Od5gUF+RUV5dOmzlZtGTzYPe5aVEFhfm9bewBAnz796hZNAACN9rEDmkqhAgCoVCr2rZGxCdb90urP283M3MHBMfLvCDqdMX7cJGzPDx6klZWX+o0brnqaVCotLyv9+MHp9M8WTQDAxxEpsvoTR2B3MGMfpDEtCuDt5XckYv+tW9cn+E9JS0tWKpWeI72bfQDUDrS62fR1YhcXF2dn56ioqMOHD5uYmAwbNgyrlZaWlm3cM6IBtBj/LfFWWclZtHgmg6E1L2hJt24WR48e+FDwvsFXUcgUhUKONab2/Xl0/8GwtT9/36+f0y/rtxoZGdd7sqBGAADQ1dVXbWGztQEAFeVlWN1k0BmfvENHIRAI27b8eSRiX/ih3ecvRK5dvdHJybmSy3F3H75owbK6z2QyP47DYzCatQqekaExAKCsrKTe9vLyUgKB0PTQhRYFMDAwHDzYPeF6zAT/Kcm3EwcNGtJx4yI6AbR+IRKJxGazKysrsW+VSmVZWRn2tUQiwf4SBgQEGBgY5ObmmpubGxsb37hxQzWRh0gkwp7Woj1j4yracRYlBLroqxe53Mo/dhwYPcqnj72DsbFpc15lZdV9+9Y/d/5x8O3b3O07Qj99grFR/UYil1upqp7tjkQiAwD4fF7djTx+FeX/W3wsFuv779acOH6RyWStD1lRW1vLZmvzeFVWVt3r/oedXzefra09jUZLSb1Vd6NQKMzIvG9v70ChUJpohbQ0gJ/vhFevnr98+Swr66HXKHzPOw6zP93Z2TkpKenevXvZ2dlbt24tKCjAtkdHR//4449xcXGnTp3icDi2trYEAmHRokWVlZUrVqyIiYmJiopauXLl1atXW7pnLS0tMzOzy5cvX7t2rbM+JdKx+PwqXV09E5OP5ZLHr8KufTcN+6PrPHCwm9vwnDfZnz7BwMDQ1MTs4cM01ZbbtxPpdHqvXnbtGv8jFotlYGB4JyVJ1eNfXFKUlfWwe/ee2LdisRg7YZ8U8LWgRlBSUuTs7Pr8+ZO6PfWtmB6MTqd7jfZ9/vxJ3c7uU5FHBAKBn+8EAICerj4AoILzsSOBw6lQzQbZ0gDubsN1dHR/2xpCJpOHDh3Z0qhqBeb1zUWLFkkkkp07dzKZTD8/P7FYzOfzsTnipFLpkSNHtLS0/P39J0+eDADw8PAIDQ2NjIz866+/mEymvb19v36NXr5pbM8AgFWrVoWHhycmJvr6+jb2cgRHBgxwuXzl3NFjBx0cnFJSbj54kKZQKHi8qiZOA19lv9iwcfXECVMZDK2HD+/a2/Vt8GlzA4O37Qj9/Y9Ngwe7Z2U9TE1LDpyzqN41zXb09bQ5+w+ELVj09fBho2QyadLNBJFINGvmfOy6YWDQ5JEjvHt0t4mKOs9isrp1swics+j+/dSfVi2d+tUsPT39hw/vyhXyzRt3tvR958/7JjPzQcivP44eNdbIyPjps0dPnz5ydfXA6qaVVXcTE9PIyAg9Xf1aYW1ExH7VYKyWBiCTySNHeEVFX/Ac6Y31reEXzLqpp6cXEhLy6fahQ4eq+n/qcnV1dXV1/XT7wIED4+LimrNnAICdnR0aAK9Jvhg+as7sBZevnLty5Zy7xxf79x3fuu2Xy1fOzg0MbuwlVArV2qrHP/8cUyqVTgMGLf92VYNP8/EZJxKLzl/4+/qNWEMDo0ULl309bU7HfZApk2cYGBidv/B3fEI0iUS2691nbmCwg4MjAEAoEg4cMDgx6VpNjaBHj15bfttNp9PNu1ns+/PowUO7//7nKIFAsLW1D5g4rRXvq6env2/vscMR++7fTxUIqgkEAo1G+/ablViXEZlMDv11x54/t/+0eqm5uWVQ4OLftq7HXtiKAH3s+0VFXxiN85N0AAChOSc17YLP57fjvMUymYxEIrVjF5ChoSGaYKnjPIyvFIvAAE/9ZjwXgenFi6er1nwrkUgc+w80MjIxMTENmru4vXZ+6dKZ4ycOXbxwvaV3cPIqpMnnimattW6vJG2kjuOQmqO2tpbBYKD7ZxEcOXxkX/TVC59u12br/B0ZpSbv6+DgePL4pUuXz2RmPsj9Nwdr8Lbds2ePE67HJFyPmTVzvgb82uK1vVlbW0ulUlt9A8anUHuzQ6H2JgCAx+fV1jZwBw6RQFT1a2nS+9Z19NjB23eS/MdPmRQwrRWniai92T7wfl0Z6YJ0tHV0tHW6zvvWNS9oybygJXAztCO8trBkMhlaXwhBECjwWjeFQqFMJoOdAkGQrqjzztNZLFY7nlzfunXL1tbW0bF9LlqjuzMRBGm+zqubRCKxHTtepk1rzVA1BEGQtsPrefqbN28KCwthp0AQpCvCa92MjY29efMm7BQIgnRFeB2HZGdnV3cdYARBkE6D17qJZuVAEAQWvJ6nl5aW5uXlwU6BIEhXhNe6+fTp07/++gt2CqS5iCRARJdVkNYiEAGVpkY/QHitm5aWlt26dYOdAmkuLW2ygIvuU0BaScCVUulqNMIar9c37e3t0aq/OGJoRsvJEsBOgeAVv1Jq1qPzFnT6LLy2NyUSyePHj2GnQJrL2IpGpRHfPkelE2mNh3Hlrj5qNJkWXusmiURatGgR7BRIC/jNM817ws97ihbFQ1qgli+P/evDzLXWBHWqVXg9TyeRSF5eXgKBgMViwc6CNNfEb7pdjyx9nsZl6VEYTLz+7CGdg6ZFLMip0WKTx8w20TVSr6mOO2/eYgTBVFfKywtFNXzUTfSf169fv3jxYtKkSbCDqBEanWjQjWZgRoUdpAE4/pv//PlzU1NTQ8OWLRiNQMfWJ7H1mbBTqJcqhTi7qLD/UMizCyPNhOP25u7duw0MDGbPng07CIIgXYs6XWttIXd3d21tbdgpEKQdSCSS6mrUY4YbOG5vIojGSEpKSkhI2LFjB+wgSLPguL0pEoni4+Nhp0CQdkClUtHJE47gu73p5eV1/vx5PT092EEQBOlCcNzeBADMnz+fx+PBToEgbVVeXv7y5UvYKZDmwnd7E0E0Q1xc3L179zZt2gQ7CNIs+G5vFhQUJCcnw06BIG1laGjYv39/2CmQ5sJ3e7O6unr8+PGodCII0pnw3d5ks9nLly/ncrmwgyBImwgEgpqaGtgpkObCd3sTQTTDxo0bnZycJkyYADsI0iz4bm8CAPLy8s6fPw87BYK0iaGhoZ2dHewUSHNpQnvT1dX13r17aFlgBEE6B+7bmwCAI0eOVFZWwk6BIK0kl8uTkpJgp0BaQBPqpqOjo5GREewUCNJKGRkZFy9ehJ0CaQFNqJsAgIULF8pkaB5cBJeqq6v9/f1hp0BaQBOubwIAtmzZYmdnN3nyZNhBEATRfBpSN2UyWU1NjY4Omi4bwRm5XJ6RkTFkyBDYQZAW0JDzdDKZTCKR0Kk6gjtXr169ceMG7BRIy2hI3QQAPHjwYN26dbBTIEjLiEQitNYL7mhO3Rw9erSWllZ5eTnsIAjSAl9//bW1tTXsFEjLaMj1TQTBo9u3b+vp6Tk6OsIOgrSM5rQ3MRcvXqyqqoKdAkE+TyAQ/Prrr6ho4pGmtTfv378fGRm5b98+2EEQgJWG2tpa2CnUlEKhAAAQiZrWdukE+vr6ZDIZYgCY790R3Nzc9PT0qqqqdHV1YWdBkKagiolfGvgv17t3b7h/ixDks/h8vkQigZ0CaSUNrJsEAiEuLm779u2wgyBIw2QyGYVCoVKpsIMgraSBdRMAMHXqVHNz8/z8fNhBEKQBZDKZwWDAToG0nmbWTQDArFmzrKysYKdANFZpaWlJSUkrXlhbW6u6sa2mpiY3N7ctMXg8np+fX2xsLPbtgQMHZsyY0ZYdfiolJcXPz+/Dhw/tu9umyeXyFy9edOY7tojG1k0AwIsXL/744w/YKRANVFxcPG/evDdv3rT0hUKhkEAgqK6/L1269Pr16x0QEPf27NmjzqNiNLluOjg4ODk5RUVFwQ6CdJJOG1Qnk8la914MBqPuGbqadA2p4WBENTkyjdHwfmdvb2/YEZD6njx5cvLkyby8PH19/QkTJpw6dSosLMzMzMzf33/u3LlTp07FnhYaGsrj8Xbt2oXdxH3ixInk5GSJRGJhYTFp0qQRI0Zgp5Bbt24NCQm5ePFiTk7OxIkTr1275uPjs2DBAmwnxcXF8+fPX7FihZeXV2N5vvrqq6VLl967d+/hw4dMJtPPz091qltZWXn48OGMjAy5XN63b9/58+f36NGjpKQkODgYALB169atW7d6eXmtWLGiic97/fr1mJiYd+/e0en0QYMGBQcHY4Pk5s6dW1VVFRMTExMTY2xsfPz48SZ28uLFi9OnT2OnrnZ2dvPnz7e1tW3N0Qfg0+M2ZcqUOXPmNHaQP/XkyZPjx4+/fftWV1fXyckpMDCQyWTOmTNn0KBBq1atwp7z9OnTNWvWhIaGDhgw4J9//rl9+3ZFRYW+vv6oUaNmzZqFrWrT2JEPCwu7c+cOAMDPzw8AcPToUVNT01Z/2I6g4XUTs2/fPm9vb7TulTp4/PhxSEiIubn53LlzaTRaVFTUZ9e/VSgUGzZsKC0tnTZtmq6u7pMnT7Zv3y4SiXx8fLAnHDhwIDAwcPbs2ebm5kKhMDk5OSgoCPvNTElJodFoHh4eTb9FWFjYzJkzp0yZkpKSEhkZ2atXL1dXV5FItHbtWj6fP2/ePBqNdv78+XXr1h0+fFhfX3/VqlU7duyYPXu2o6PjZ0cKZ2dnW1hYuLu7i8XiqKgooVAYGhoKAFi3bl1ISEj//v0DAgIoFErTOyktLZVIJNOnTycSibGxsb/88suxY8fodHrTr2pa3eP22YOs8vjx419++WXUqFH+/v58Pj8qKmrt2rV79uwZNWpUQkKCUCjEGtS3bt0yNjZ2cXFRKpWPHz8eMmSImZlZXl7e2bNn2Wz2pEmTmjjy06ZNKy8vLykp+fHHH7FR7m35mB2hS9TNb7/9dtu2bTNmzEA9RdAdPXqUzWaHhYVpaWkBAJhM5tatW5t+SVpa2osXL44dO2ZgYAAAGDlypEgkioqKUv1Kjx8/XtWc9PLyio2NzcrKGjx4MAAgNTXV1dUVe68mjBkzZtq0aQCAnj17JiQkZGVlubq63rp168OHD1u2bBkwYAB22WfevHl2MdzjAAATQUlEQVTR0dEzZsywsbEBAFhYWDg4OHz2Iy9btoxAIGBfk0iks2fPisViGo3Wu3dvEomkr6/fnJ14enqOGjUK+9rW1nbt2rUvX750dnb+7AubUPe4paSkNH2QVcLDw319fZcsWYJ96+zsHBwcnJWV5evrGxUVlZaW5uXlJRaLU1NTJ0+ejI3t37Vrl+oIFBcXp6Wlqepmg0fe3NxcR0enqqqqOUcGii5RNwEAa9asAQCUlJSoW4O/S6murs7NzZ00adJnC1ld6enpMpls3rx5qi1yuZzJZKq+xeoaxs7OztraOikpafDgwcXFxbm5udOnT//sW6gabiQSycDAgMPhYGeaTCZTtXMTExNLS8ucnJzmJ8cay3w+PzEx8ebNm+Xl5TQaTaFQ8Hg8Y2PjFu2HQCDcvXv30qVLHz58wBp0XC63RXv4VN3j9tmDjCktLc3Pzy8qKoqPj6+7vby83MPDw8HB4datW15eXvfv3xeLxaqaW1VV9c8//2RlZQkEAuyPpeqFDR559ddV6ibm3LlzY8eO7d27N+wgXRT2a2NoaNiiV3G5XH19/XrN0rq3hNUbC+nt7X3y5EmBQJCamspkMl1cXFr0dmQyWS6XYwOG6q0gwGazW7pyanV19Y4dO968eTNz5kx7e/u7d+9euHABuzO9RU6fPn3q1KkJEyYEBQVVVlZu3bq1FTupp+5x++xBVj0NADBjxoyhQ4fW3Y6dSvv6+oaFhVVWVt66dcvd3V1PTw97ybJlyxgMxuzZs83MzE6ePFlYWNhgHtWRV39dq24uX748NDQUu7qEdD7sF6nBNoXqPO5TLBYLa6DRaLTmvIunp+exY8fu3LmTmpo6bNiwz146bIyBgUF2dnbdLVwut/krp0qlUgqF8v79+8ePH69atWrkyJEAgKKionpPa05ftlgsPnfunI+PD9Yf1RGTzDbzILNYLCyPpaXlp48OHTr00KFD0dHRmZmZmzdvxjbGxcVVVVWFhYVhTWxjY+PG6mY9atjLr6LJ45AahBVNrLcO6WR0Ot3a2jo5OVkoFNZ7iEQi1W3NKZXKsrIy7OsBAwbI5fK4uDjVkz99eV16enqDBw++ePHimzdvGusRbo4+ffpUV1erSufbt2+LioqwK25YcWnipLKmpgZrD/L5fAAAdj1U9a2qItDp9OY0YEUikVgsVnWgYzvB9o/9VaiursYeolAoIpGoFQvGNHGQ676Fubm5sbHxjRs3VI/KZDKpVIp9TaPRPD09z58/361bNycnJ1VaHR0d1XUJHo/XnIJIp9O5XG7b29QdhNQ1G1/p6ekZGRmqf1qkg0gkEtUvFUZbW/vGjRsPHjxQKBR5eXlXr17lcDjjx4/X0dHJy8tLS0uztLSsqak5fPjwy5cv9fX1x44da21t/ejRo8TERD6fz+VyExMTw8PDx44dSyaT8/PzU1NTsZfXfRcCgRAfH6+vr7948eImWrKY8+fP9+rVS9XHcu3aNS0trREjRlhbW9+5c+f27dsMBuPff//dv38/mUz+4YcfGAyGlpbWzZs3X758yWAwHj161KtXr3qntEqlEqutWlpasbGxZWVlWlpaaWlpp0+flkqlTk5OWHvt33//vXv3LolEys/Pp1AojXXN0+n0tLS07OxsAwOD169f79+/XygUmpiYuLi4UCiUmzdvPn36lMVi2dra8ni8O3fuvH37tnfv3mw2u7GP/Olxa+Igk8nkq1evvn792sLCwtTU1NjYOCEh4cGDBwCAV69ehYeHy2Qye3t7bD9GRkYxMTFff/21aotEIrl+/bpcLpdKpefPn09LS6utrf3yyy/pdHpjRx67pHP79m0OhyMQCMrKyiwsLOrmZzAYcGeT6qJ1s2/fvuXl5T179oQdRMN9Wjetra319fWfPXuWmpr6/v17CwuLDx8+YL/ADg4O79+/v3z58oMHD4YMGUImk8Vi8dixY0kk0vDhwwUCQUpKSlpaWk1NzZgxYxwcHIhEYmN1k8FgXLlyxcfHpzkXNxv77SUSiUOGDHn37l1sbGxGRkavXr3WrFljYmKC1WV7e/vMzMzbt2+Xlpa6u7urTmBlMhlWa7C9aWlpWVlZJSYmJiYmymSyVatWcTicFy9eYB3Z9vb2eXl5t27d+vfff3v37t3gyS+mX79+GRkZMTExBQUFQUFB5ubm165dCwgIIJFI9vb2r1+/fvv2rY+Pj7W1tUgkyszMtLOzq1dr6vr0uDVxkFkslomJyZMnT4hEorOzs6Wlpa2t7YsXL5KSknJycnr06DFq1CjVUCFdXd2XL1/OmTNHdb5vZWWlUChiY2PT0tK6dev23XffvXjxQigUOjo6NlE3u3fvXl1dnZyc/OzZMx0dnbpdWOpQNzVt3uKW+u2336ZPn44KaAf57LzF2ADsQ4cONVEyWuHt27dLly7dvXt3Z/YBKpVKgUDQRCsPaS9o3mLIVq5cuWDBgsjISNhBkPZRVlYWGxt7/fp1R0dHVdF8+PDh77//3uDzd+7c2fZRvffu3QsLC2vj/ts3ZE1Nzdy5cxt8aP78+WPHjm3R3pB6unp7UyUtLa3e0Aqk7Tq/vZmVlRUWFjZs2LDAwEDVOBuRSNTYqlOGhoZtbLlIpdImejCav//2DalQKFQda/Voa2u3aPysGoLe3kR186P3798HBgbGx8e38d41pC7NXl8Iu5SJ/R92lq4F1U01Ul1dzePxGAwGdqsZ0nYaXDdra2vlcjm6mgkF9LrZ5cZvNoHNZltYWJBIpIkTJ1ZUVMCOg6gpbHQkmUxGRbPLQu3NBhQUFDx48GDy5Mmwg+CeQCAQiUSwU7QbbDQ+m83G+/VBvNPV1UXn6epr8eLFCxcuHDRoEOwgCGQymUwkEnG5XB6P169fP9hxEMjQeXpTduzYceXKFdWpGdI1Yfe5k8lkS0tLVDQR1N5srujoaB6PN3v2bNhBkE715s0bW1vbuLg4bOJxBMGg9maz+Pv7czgc7J5cpCsQCoXz5s3D1qVARROpB7U3WwBbA+Cnn3769ttvra2tYcdBOsT79+8tLS3z8/N5PB6a+QVpEGpvtgB2/8m0adO2bduGLnpqpAMHDvzwww8EAqF79+6oaCKNQe3N1rt3715mZua3334LOwjSVjwer7i42N7e/vbt222ZshPpIlB7s/Xc3d2ZTGZ4eDjsIEibPHz4MCAgAFv0BhVNpDlQe7N9rFmzpl+/frNmzYIdBGmumpqa+Pj4yZMnv3z5sm/fvrDjIHiC2pvtY/PmzRUVFTwer7EpbRD1gc097uvri82vjoom0lKovdmelEolh8OZPHny7t27Bw4cCDsOUp9AINi3b19AQICNjQ2axAhpNdTebE8EAsHQ0DA2NhZbxCo2Nhb1uasJbKIWbGEGOzs7VDSRtkDtzQ4UHR29ZcuW+Pj4xtbbQjqBRCIJCQnR1tb++eefYWdBNASqmx2uurqaRqNt27YtODgYW9UL6RwZGRkDBgwoKyt7+fIltg4agrQLdJ7e4dhsNpVKdXJywkYsNbZ6AdK+wsLCjhw5QiQSu3Xrhoom0r5Qe7OzJSYmHj9+fMOGDTY2NrCzaKALFy7o6emNHj36w4cP7btGJoKooPZmZ/Py8lq/fn1RUREAID4+HnUctQuxWAwAOHPmzJs3b9zd3QEAqGgiHQe1N2G6dOlSbGxsRESEVCqlUCiw4+BVWFhYTk5OeHg4WiIN6RyovQnTpEmTIiIisJU5VqxY8e7du0+fM2bMmDNnzsBIp0YaXO/71atXHz58AABYWVlh145R0UQ6B6qbaqFHjx4TJkxISkoCALx+/bruQ1wu9+TJk1156s9Zs2aVl5f7+/vX3fjPP//89ttv2MpoU6ZMgZcO6YpQ3VQXI0aMmD9/PgAgPz/fy8uroKAAa5Bia4Ft3769pKQEdkYIQkNDc3JyCARCaWkpNiQWa6EPHTo0MjISDYxFoEB1U+14e3ufP38e6y/CqidWTFeuXAk7Wmc7ceLEnTt3FAoFNtvp8+fPHz16NHHiRAAAmjcagQj1C6k1FxcX1dcEAmHUqFHbt2+HmqjzpKambtu2rW4rm0ql3r17F2ooBAGovanWRo8eXfdbpVJ59+7dvXv3wkvUeYqLi8PCwupdmpBIJPASIch/UHtTfWHrtiuVSiKRqPpnYrPZycnJTbyqskTCKZbU8mW11XKlQikRq9e/rxaLBAhAS5vE1KaY9aDTmQ3/5Q4ICMjPz1d9q1QqCQSCUqlkMpkpKSmdmBdBGoDGbagvLy8vEolEo9HYbDaDwaBQKEwmE+tB/lTpe9HrTMG/TwVUBplIJpGoJBKZRKRQFAr1qptVfKJMLJFLpQSCiFtUomtEtR3I7O+hQ6H/TwFdvXp1SUmJUCiUSCQikaimpkYikchkstraWnjZEeQj1N7EPW6ZNOVKhVhMJFAo2sZMKgNPfwtrq8SCihpeicDBTdtjvAHsOAjSLKhu4ltqVGVOVrVhT31tYy3YWdqE866q+A13bKBZLycm7CwI8hmobuLYhT2FVG2WtikLdpB2ogSFz0t7OdKHjNWHHQVBmoLqJj4pwckt+QbdDZj6dNhR2lnFW24PO8qg0TqwgyBIo1DdxKWjv7zr1t+EzqLCDtIhyv+tNDQGnlONYAdBkIah8Zv4c+VgkXFvA00tmgAAIxv98mLF87s82EEQpGGobuJMxg0ukcZgGeC7F+izjHsbZmeJyj6IYQdBkAaguoknYqEi4wZX20wbdpDOwNBj3TpfDjsFgjQA1U08uXOpwsS2q/Q1M/XpUinh3csa2EEQpD5UN3GjmiurLJPrWTR8vxBcf5//Zfueqe2+W6MeBk9Tq9t9twjSRqhu4kbeMwEgkmCn6FQ0NqU0XyioQkswIeoF1U3cyH1Sw9T07qBPsY2Yec8FsFMgyP/A073MXZlMCsRCpUEvRkfsXCIRXUs8+OhpglQqNjK0Hjls5oD+3gCAO3dPP36W+IXH9GuJB6urK8y72X81Ya2xUXfsVY+f3bh+6wi3qtjEqKdSqeiIYAAAtiGzOK/GcVgH7R5BWgO1N/GhulIirJF3xJ4VCsXRv1e+zE4Z9UXg5AlrzM16R55b/yAzGns0v+D57bS/v5qwLnD6jipe6ZlLG7HtWU8SIs+t12YZTPRbaWfrVlTypiOyAQDINFLxW2EH7RxBWge1N/Ghhi+n0Drk4uazl7fevnu8buUVHW0jAICzo49YUpt67+yQQR/XQQua+Yc22wAAMMxt6tX4PTW1PCqFHhUX1tN64MLAvSQSCQBQwfnQQaWTQiMLa9D1TUS9oLqJDzV8GZnaIf9Yr16nyRWyLWEBqi0KhZxB/2+uEBr148UBPV0zAACfX14tqKyprRru8TVWNAEAxA7rsCKSCUolkEqUFCqhg94CQVoK1U386Ji6US3gaLMNFwftr7uRSGzgB4NMomBVlcsrAQDo65p1SCAEUXuobuIDU5ssl3TI6aoWQ1tQw9XTNaNQaM18CYupBwAQ1FZ1RJ56FDIlkQBQYxNRK6hfCB+Y2mSpqEP6hXrZDFYo5HcfXlRtEUs+0w/TzdSWQCBmPYnviDz1SMUyBhv9dUfUC/qJxAe2AYXB7JBriIOcfB9kXIlJ2MutKjY3sysqefPsZfKq5Wep1EZn9tTTNXV1Hv8gM0omE9vZuvOrK17lpLFZHbLKhVQkN+vZIaOvEKTVUN3EBzIZ0LSIAo6QZdDORYRMpiwM/DPu+v5HT6/fS79sZGDl4TqJRPrMD8bEL1eSydRHTxNe5z7oYeXUzbR3tYDTvsEwNRyBtYumzc2M4B2atxg3nqZUvcqSmPTuWouXvUnNn7HKkqmD/sAjagT9OOJGz36s7Mym5lVTKBS/bPVu8CGWlm6D3TgO9l9Mn/xreyUUigS/7ZzQ4EPWlv3ff3j26fZupr2/mX+wsR2Kq6WmPRioaCLqBrU38STpTBm/mtrElEiV3KIGt8tkUjKZ8ul2KpWBdY63C4VCUcUrafgxJQEQGvhJI5Op2mzDxnZY8LTkiwl6VvZd7q58RM2huoknEpEi4pe3fTy7ww7SGWoqRbUVVV99Zw47CILUh8Yh4QmVThziY1BdyocdpDOIedUjp6Cl2RB1hOomzjiP1lWKhQJOLewgHavsTbm9s5aRucauPYfgGqqb+OMf3K08lyPka+yaZWW5HBNzUl+3LrGMEoJH6PomXkVu/aBnpcfU17Qx4RV5lb36UQeM0IEdBEEaheomjl3aV0hlMVkm6rjiUCsoFcril6W2A7QGe7dbFz+CdARUN/HtwbXK5/f5Rj31tY2ZsLO0Ced9VWku98t53az7olFHiLpDdRP3eBXS1Cuc2lpAoFDZRlo0ZgPjNNVWDVdUU1FbVVztOFzXza+rLHGM4B2qmxqi7IM4J7M692kNmUoikklkKolIIZGoZKVCvf59iSSiVCRRSOQEgrKysFbfjNp7IKufhw4ZzRSH4Aeqm5qGWyrllIhr+fIavkwhV0rF6vXvy2CRCETA1CazdMhmPehUBhrRgeAPqpsIgiAtg/7aIwiCtAyqmwiCIC2D6iaCIEjLoLqJIAjSMqhuIgiCtAyqmwiCIC3zf54LyBLs3t7NAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display # type: ignore\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "VUVNuUO3Bw2I"
      },
      "outputs": [],
      "source": [
        "inputs = {\"question\": \"Explain how the different types of agent memory work?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Kh7HJ4Bw2K",
        "outputId": "a815291d-2259-4602-fc64-141bc928763f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----DECISION: GENERATE----\n",
            "----GENERATE----\n",
            "---CHECK HELLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION ---\n",
            "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='This document describes two types of agent memory: short-term memory, which is used for in-context learning, and long-term memory, which stores information for extended periods often using an external vector store.  Long-term memory allows the agent to recall past information and use it to inform future actions. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 2080, 'total_tokens': 2146, 'completion_time': 0.12, 'prompt_time': 0.070844905, 'queue_time': 0.024502522, 'total_time': 0.190844905}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-a2ba82a7-0f7e-471c-9bb0-c8743305a46e-0', usage_metadata={'input_tokens': 2080, 'output_tokens': 66, 'total_tokens': 2146})"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "app.invoke(inputs)[\"generation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "nKj890ekBw2L"
      },
      "outputs": [],
      "source": [
        "inputs = {\"question\": \"who is a prompt engineering?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2KflL5FBw2M",
        "outputId": "43a6cbd7-40fd-4c78-b7e0-fec87d65d3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----DECISION: GENERATE----\n",
            "----GENERATE----\n",
            "---CHECK HELLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION ---\n",
            "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Prompt engineering is the art and science of designing effective prompts for large language models (LLMs) to elicit desired responses.  It involves carefully crafting input text to guide the LLM's behavior and generate specific, accurate, and relevant outputs.  Think of it like giving clear instructions to a very intelligent but literal-minded assistant. \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 1009, 'total_tokens': 1080, 'completion_time': 0.129090909, 'prompt_time': 0.032722132, 'queue_time': 0.024065117999999996, 'total_time': 0.161813041}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f06f46f8-ae68-403d-a25d-ab8329b50c66-0', usage_metadata={'input_tokens': 1009, 'output_tokens': 71, 'total_tokens': 1080})"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "app.invoke(inputs)[\"generation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ceQ5RDinBw2P"
      },
      "outputs": [],
      "source": [
        "inputs = {\"question\": \"what is role of data structure while creating ai agentic pattern?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "xOq8YipMBw2Q"
      },
      "outputs": [],
      "source": [
        "inputs = {\"question\": \"what is role of c language and php while creating ai agentic pattern?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPYHM_cABw2Q",
        "outputId": "4f5935dd-54c7-44d5-c2fa-abf8625936bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----DECISION: GENERATE----\n",
            "----GENERATE----\n",
            "---CHECK HELLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION ---\n",
            "---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---TRANSFORM QUERY\n",
            "this is my document[Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#')]\n",
            "----RESPONSE---- how do agents utilize components like planning and memory when leveraging  LLMs? \n",
            "\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----DECISION: GENERATE----\n",
            "----GENERATE----\n",
            "---CHECK HELLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION ---\n",
            "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'how do agents utilize components like planning and memory when leveraging  LLMs? \\n',\n",
              " 'generation': AIMessage(content='Agents use planning to break down large tasks into smaller, manageable subgoals, enabling them to handle complex tasks efficiently.  They leverage memory, both short-term (in-context learning) and long-term (external vector stores), to retain and recall information, guiding their planning and decision-making.  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 1937, 'total_tokens': 2001, 'completion_time': 0.116363636, 'prompt_time': 0.080231297, 'queue_time': 0.022286523000000003, 'total_time': 0.196594933}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-819b0e9d-9c65-4d0b-b242-abf0c6b447c4-0', usage_metadata={'input_tokens': 1937, 'output_tokens': 64, 'total_tokens': 2001}),\n",
              " 'documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
              "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
              "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#'),\n",
              "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#')],\n",
              " 'filter_documents': [Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
              "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.'),\n",
              "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#'),\n",
              "  Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#')],\n",
              " 'unfilter_documents': []}"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "app.invoke(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "SkvxWnSGBw2R"
      },
      "outputs": [],
      "source": [
        "inputs = {\"question\": \"who is a first president of USA?\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HhyV6UlBw2S",
        "outputId": "a0a91081-1392-4728-fabe-80ce3944dd2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
            "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Definition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='},\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='},\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",')]\n",
            "----RESPONSE---- question not relevant \n",
            "\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
            "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"')]\n",
            "----RESPONSE---- question not relevant \n",
            "\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
            "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"')]\n",
            "----RESPONSE---- question not relevant \n",
            "\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
            "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"')]\n",
            "----RESPONSE---- question not relevant \n",
            "\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----GRADE: DOCUMENT NOT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----ALL THE DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY----\n",
            "this is my document[Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='Later, Shum et al. (2023) found that in their experiments CoT prompts with only complex examples can improve the accuracy of complex questions, but perform poorly in simple questions; evidence shown on GSM8k.\\n\\n\\nChanging Q: to Question: is found to be helpful. (Fu et al. 2023)'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"')]\n",
            "----RESPONSE---- How does a language model, like those used in agent systems, utilize short-term and long-term memory? \n",
            "\n",
            "----RETRIEVE----\n",
            "----CHECK DOCUMENTS RELEVANCE TO THE QUESTION----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----GRADE: DOCUMENT RELEVANT----\n",
            "----ACCESS GRADED DOCUMENTS----\n",
            "----DECISION: GENERATE----\n",
            "----GENERATE----\n",
            "---CHECK HELLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION ---\n",
            "---DECISION: GENERATION ADDRESS THE QUESTION ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Short-term memory in language models is analogous to in-context learning, using the current prompt and previous interactions.  Long-term memory is achieved by storing information externally, often in a vector store, allowing the agent to recall past experiences and knowledge. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 2113, 'total_tokens': 2168, 'completion_time': 0.1, 'prompt_time': 0.068442211, 'queue_time': 0.026809375999999996, 'total_time': 0.168442211}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d504b23-9146-470e-981e-f339615d7ca5-0', usage_metadata={'input_tokens': 2113, 'output_tokens': 55, 'total_tokens': 2168})"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "app.invoke(inputs)[\"generation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "l5rDsnQgBw2S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27083a2470134b2fafb45f94cc1a3b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1335abbb7b6467b88130efaa6526a1c",
              "IPY_MODEL_2fc7a928f3d74fdeb9e5d081eacad808",
              "IPY_MODEL_955fe0d4d4c849f59d287c90bf90d716"
            ],
            "layout": "IPY_MODEL_908b53c275e748d48c8d8778434d01e5"
          }
        },
        "a1335abbb7b6467b88130efaa6526a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a81c31257542ebbdccd2d9a3c38c83",
            "placeholder": "​",
            "style": "IPY_MODEL_12b45a8f25f14ceb8d387a364166ed22",
            "value": "modules.json: 100%"
          }
        },
        "2fc7a928f3d74fdeb9e5d081eacad808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4281dfaca00544a297d0c2ab14d31400",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3349d880c6d3485a8cc92a2408d82341",
            "value": 349
          }
        },
        "955fe0d4d4c849f59d287c90bf90d716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0640e5cd238341b1ac49431d5d074a37",
            "placeholder": "​",
            "style": "IPY_MODEL_d97f4885648343a3b3d2bef44f9d0813",
            "value": " 349/349 [00:00&lt;00:00, 19.0kB/s]"
          }
        },
        "908b53c275e748d48c8d8778434d01e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67a81c31257542ebbdccd2d9a3c38c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b45a8f25f14ceb8d387a364166ed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4281dfaca00544a297d0c2ab14d31400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3349d880c6d3485a8cc92a2408d82341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0640e5cd238341b1ac49431d5d074a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97f4885648343a3b3d2bef44f9d0813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e49dc12b32445c69367e02c9274b7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb40f30b2c04bd2a44121e2d7c4b9b7",
              "IPY_MODEL_01543f0d2cb949e9b75ad57a53794415",
              "IPY_MODEL_6d751f8a1b9140cb87dcf3d8de4688c4"
            ],
            "layout": "IPY_MODEL_66c2b702ed504ea98fe769fa332ad7ec"
          }
        },
        "4eb40f30b2c04bd2a44121e2d7c4b9b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_388ea664ba8e4e0c966d14572d2cf44a",
            "placeholder": "​",
            "style": "IPY_MODEL_7424ca6b3e9a4955a792693c507273f3",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "01543f0d2cb949e9b75ad57a53794415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45668a43f544f39995b0786baecc014",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a49ad4ea5c34342acc8d28afdbaa019",
            "value": 116
          }
        },
        "6d751f8a1b9140cb87dcf3d8de4688c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0feedebb4134c82abbe364af6edf0d3",
            "placeholder": "​",
            "style": "IPY_MODEL_fe75f0d5157d4ad1bb9cb933409e5a22",
            "value": " 116/116 [00:00&lt;00:00, 7.15kB/s]"
          }
        },
        "66c2b702ed504ea98fe769fa332ad7ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "388ea664ba8e4e0c966d14572d2cf44a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7424ca6b3e9a4955a792693c507273f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a45668a43f544f39995b0786baecc014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a49ad4ea5c34342acc8d28afdbaa019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0feedebb4134c82abbe364af6edf0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe75f0d5157d4ad1bb9cb933409e5a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45fa10027e874587a6903fa734fb87e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1ae736823a84be7b815f6e0054c4c44",
              "IPY_MODEL_cf6cabc6900142a3abd1aa951c2fb675",
              "IPY_MODEL_ffbd6cb3ac0842a7bad21b6486feb6df"
            ],
            "layout": "IPY_MODEL_7d8970b37355436d89f4fc3733677927"
          }
        },
        "c1ae736823a84be7b815f6e0054c4c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d64db5cfb92b4a4dbb392b437b0d0496",
            "placeholder": "​",
            "style": "IPY_MODEL_de2936151e83499e969c324866477d51",
            "value": "README.md: 100%"
          }
        },
        "cf6cabc6900142a3abd1aa951c2fb675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04a52c6e860c4986b0aa546e5c32add8",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec4f8eafb2b141aeaa0b538d8edaf519",
            "value": 10659
          }
        },
        "ffbd6cb3ac0842a7bad21b6486feb6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f54faabce004b3594c74eed3c6d2373",
            "placeholder": "​",
            "style": "IPY_MODEL_64b3491fd65643119daa9be16020c7e3",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 566kB/s]"
          }
        },
        "7d8970b37355436d89f4fc3733677927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64db5cfb92b4a4dbb392b437b0d0496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de2936151e83499e969c324866477d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04a52c6e860c4986b0aa546e5c32add8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4f8eafb2b141aeaa0b538d8edaf519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f54faabce004b3594c74eed3c6d2373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b3491fd65643119daa9be16020c7e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b63c5f9c57644fe0ba03fb54fd664a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b630c903ea497bbfab04ad5641a9d2",
              "IPY_MODEL_f875629344af44058df0dc6851fb369d",
              "IPY_MODEL_b0605807ce5245248da119b73fd54ea6"
            ],
            "layout": "IPY_MODEL_893655cec0714274b3c39d87c68c37e5"
          }
        },
        "b3b630c903ea497bbfab04ad5641a9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27bc9a01bed84859a828d56b8ca8ea90",
            "placeholder": "​",
            "style": "IPY_MODEL_c936e9d84e96480e80114444721e28c0",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "f875629344af44058df0dc6851fb369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a2dfc89df14081a216690e0da3cf40",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_273ca287ef7c4b1c871617c099177241",
            "value": 53
          }
        },
        "b0605807ce5245248da119b73fd54ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_804c4e02e2ce47199e6f1150810f863a",
            "placeholder": "​",
            "style": "IPY_MODEL_f77158f6ca9543e89915a2089bb31cd8",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.03kB/s]"
          }
        },
        "893655cec0714274b3c39d87c68c37e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27bc9a01bed84859a828d56b8ca8ea90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c936e9d84e96480e80114444721e28c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57a2dfc89df14081a216690e0da3cf40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "273ca287ef7c4b1c871617c099177241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "804c4e02e2ce47199e6f1150810f863a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77158f6ca9543e89915a2089bb31cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "074a29b8f1e14cea8ce63eba0b89236d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00d1bb4ea0de4cc19de903bf131055d7",
              "IPY_MODEL_63e524a5e7d54906b74baa73fb1f4771",
              "IPY_MODEL_02a2fa37da754edfa279229a0f8c33af"
            ],
            "layout": "IPY_MODEL_dfbed2653b7b49cca43ffa14cb4b08cb"
          }
        },
        "00d1bb4ea0de4cc19de903bf131055d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9b62ae15684a19ab9064e32e35487a",
            "placeholder": "​",
            "style": "IPY_MODEL_af3dd13038dd49e69e630439a1f25e71",
            "value": "config.json: 100%"
          }
        },
        "63e524a5e7d54906b74baa73fb1f4771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_121d027da5df459fad95ab85929252a6",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8670c3b388e4445b6effe6fa64eaaab",
            "value": 612
          }
        },
        "02a2fa37da754edfa279229a0f8c33af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85dbd3efca274ed69a3db69e0d7cda0c",
            "placeholder": "​",
            "style": "IPY_MODEL_b3d9ae034ac34668953fd42b75219376",
            "value": " 612/612 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "dfbed2653b7b49cca43ffa14cb4b08cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9b62ae15684a19ab9064e32e35487a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3dd13038dd49e69e630439a1f25e71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "121d027da5df459fad95ab85929252a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8670c3b388e4445b6effe6fa64eaaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85dbd3efca274ed69a3db69e0d7cda0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d9ae034ac34668953fd42b75219376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a683250fa9cc46a2a2dee63d73cb98d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1967f63ebd0f4bf0848f49e2646f74aa",
              "IPY_MODEL_5f615e7241a74496b5c94754c5576246",
              "IPY_MODEL_e534fcda54894af7b162a860637f744e"
            ],
            "layout": "IPY_MODEL_46b403937a7c48dd8561b224729f5bc3"
          }
        },
        "1967f63ebd0f4bf0848f49e2646f74aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76cf8cbf2fb41efb913a9c7729ef1dd",
            "placeholder": "​",
            "style": "IPY_MODEL_7d39fe0bc6a24b87a8beb5071f47a8fa",
            "value": "model.safetensors: 100%"
          }
        },
        "5f615e7241a74496b5c94754c5576246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d7e43276e7f483d841621d6786e843b",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e6447c8d5bf41ef855eb7d7ae2a596b",
            "value": 90868376
          }
        },
        "e534fcda54894af7b162a860637f744e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a9e83c139a4b9fa2f90983693e2b32",
            "placeholder": "​",
            "style": "IPY_MODEL_e07a81bb7a714f07a00c6ce9026bb7eb",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 110MB/s]"
          }
        },
        "46b403937a7c48dd8561b224729f5bc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76cf8cbf2fb41efb913a9c7729ef1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d39fe0bc6a24b87a8beb5071f47a8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d7e43276e7f483d841621d6786e843b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6447c8d5bf41ef855eb7d7ae2a596b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13a9e83c139a4b9fa2f90983693e2b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07a81bb7a714f07a00c6ce9026bb7eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9414717cc649496681ec80126da3ef61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c6f89f3503a4b5db3e241d264f8e18e",
              "IPY_MODEL_4c6961f25f7b49779acfc9b663415d61",
              "IPY_MODEL_cae7290a44734d878c680760589e0fe7"
            ],
            "layout": "IPY_MODEL_d4fd08552ca84b4e9a2b844baacc8ece"
          }
        },
        "4c6f89f3503a4b5db3e241d264f8e18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dda21ff6fcaa46db8a91ac1fc043ca36",
            "placeholder": "​",
            "style": "IPY_MODEL_351b955d288b451d835b935cd3887bff",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4c6961f25f7b49779acfc9b663415d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c973df50712a454b8a3c8a01ddaa6557",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9011fc516dbe42b8883a3a2260c41d18",
            "value": 350
          }
        },
        "cae7290a44734d878c680760589e0fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edfa1145f1d847ad8916a15133856e44",
            "placeholder": "​",
            "style": "IPY_MODEL_5613a8962e494332a2a769beeed1f37a",
            "value": " 350/350 [00:00&lt;00:00, 6.59kB/s]"
          }
        },
        "d4fd08552ca84b4e9a2b844baacc8ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dda21ff6fcaa46db8a91ac1fc043ca36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "351b955d288b451d835b935cd3887bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c973df50712a454b8a3c8a01ddaa6557": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9011fc516dbe42b8883a3a2260c41d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edfa1145f1d847ad8916a15133856e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5613a8962e494332a2a769beeed1f37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7ce43d15c37421bb8acb52f1ee4cda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85d9ae3899f94f179e2961ff4b0589da",
              "IPY_MODEL_3ff6d9a74ac44daba464dca2e7cb4a86",
              "IPY_MODEL_c7ad40add5394b659508d5b2c6eca34d"
            ],
            "layout": "IPY_MODEL_2be37cd4c3894c37a19bbbaf2acf306f"
          }
        },
        "85d9ae3899f94f179e2961ff4b0589da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6f009684df4d819fd5b72a0517a4bd",
            "placeholder": "​",
            "style": "IPY_MODEL_a4091215c71e4450981999a2680f9686",
            "value": "vocab.txt: 100%"
          }
        },
        "3ff6d9a74ac44daba464dca2e7cb4a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fc9026b959b4db6904705243972793b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_755a3818c94844779f2223236b107f6c",
            "value": 231508
          }
        },
        "c7ad40add5394b659508d5b2c6eca34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e942e31eadc94bc2addcd88f668affe4",
            "placeholder": "​",
            "style": "IPY_MODEL_ec6dccdc909c44278e9940ee24a09679",
            "value": " 232k/232k [00:00&lt;00:00, 1.80MB/s]"
          }
        },
        "2be37cd4c3894c37a19bbbaf2acf306f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6f009684df4d819fd5b72a0517a4bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4091215c71e4450981999a2680f9686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fc9026b959b4db6904705243972793b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "755a3818c94844779f2223236b107f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e942e31eadc94bc2addcd88f668affe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6dccdc909c44278e9940ee24a09679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f868af1bb5324daead6bb34e27b21bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd547f13269340d1b3e7f4d445d3f533",
              "IPY_MODEL_7d755fe2b905465a895369e67401343a",
              "IPY_MODEL_67483644ca094d439af2153121a5b0fd"
            ],
            "layout": "IPY_MODEL_dc40c684690f4832aaf1b1cddafb7eac"
          }
        },
        "cd547f13269340d1b3e7f4d445d3f533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeec603384c344958f7634816ca41e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_b5c261340b314b5b8c562915134f63d5",
            "value": "tokenizer.json: 100%"
          }
        },
        "7d755fe2b905465a895369e67401343a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b4780df0be24c23a80f87b1929269d8",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cbe2ec957ff4ff0ad51d8b4356f338e",
            "value": 466247
          }
        },
        "67483644ca094d439af2153121a5b0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdfe3d6c967a45eaa37a0b15ebaa939c",
            "placeholder": "​",
            "style": "IPY_MODEL_3313e105a1cf4c21be203d13825cdbed",
            "value": " 466k/466k [00:00&lt;00:00, 7.14MB/s]"
          }
        },
        "dc40c684690f4832aaf1b1cddafb7eac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeec603384c344958f7634816ca41e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5c261340b314b5b8c562915134f63d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b4780df0be24c23a80f87b1929269d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbe2ec957ff4ff0ad51d8b4356f338e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdfe3d6c967a45eaa37a0b15ebaa939c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3313e105a1cf4c21be203d13825cdbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1ff6efc0d42400fa621f3a7198afe00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a834370aa22b438f97e23e3b7a99ca82",
              "IPY_MODEL_9c7e7bac37ed4d5e8eb10e2ec328c097",
              "IPY_MODEL_8cd5bd7bc2b244feb59c0c5ddd237505"
            ],
            "layout": "IPY_MODEL_ceeba63681e04aa0b1538db50c3a11ad"
          }
        },
        "a834370aa22b438f97e23e3b7a99ca82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43195e09702c48019bafcf93286753f6",
            "placeholder": "​",
            "style": "IPY_MODEL_192dce2989304f1d9d648e5e2efed6a5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "9c7e7bac37ed4d5e8eb10e2ec328c097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_054ff1468a204087b2b8e5340f574320",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0e57558d8504b5db4ee26242b1d3811",
            "value": 112
          }
        },
        "8cd5bd7bc2b244feb59c0c5ddd237505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1850d3c295c74753bb7232dc976fbd73",
            "placeholder": "​",
            "style": "IPY_MODEL_babcc9b4b5654f5e8b7d167493cc1d81",
            "value": " 112/112 [00:00&lt;00:00, 2.42kB/s]"
          }
        },
        "ceeba63681e04aa0b1538db50c3a11ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43195e09702c48019bafcf93286753f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192dce2989304f1d9d648e5e2efed6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "054ff1468a204087b2b8e5340f574320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e57558d8504b5db4ee26242b1d3811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1850d3c295c74753bb7232dc976fbd73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "babcc9b4b5654f5e8b7d167493cc1d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fea2049e512492ca2eb0e32707ac00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f4eaa2f16964eb59c8b501e913a0dcb",
              "IPY_MODEL_f24b7830eeea4c7ab1801bee9830a0c0",
              "IPY_MODEL_ac3fc9e1dd0641148c724f4dad61df49"
            ],
            "layout": "IPY_MODEL_325a9a169ec2419898d0440d2fafd674"
          }
        },
        "2f4eaa2f16964eb59c8b501e913a0dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c6f998695148e9a470d7eb4e4a49ed",
            "placeholder": "​",
            "style": "IPY_MODEL_1a2f39af53044ec798c353898667f29e",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "f24b7830eeea4c7ab1801bee9830a0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_468b35ad872944969ada599122bf118e",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_203975b69e514efbadeac8bed565b3ca",
            "value": 190
          }
        },
        "ac3fc9e1dd0641148c724f4dad61df49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31a7ca84b5d44d08b47b034eb4aead09",
            "placeholder": "​",
            "style": "IPY_MODEL_b21c1370c37f44deb1bd9f54f147c07b",
            "value": " 190/190 [00:00&lt;00:00, 3.00kB/s]"
          }
        },
        "325a9a169ec2419898d0440d2fafd674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c6f998695148e9a470d7eb4e4a49ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a2f39af53044ec798c353898667f29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "468b35ad872944969ada599122bf118e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "203975b69e514efbadeac8bed565b3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31a7ca84b5d44d08b47b034eb4aead09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21c1370c37f44deb1bd9f54f147c07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}